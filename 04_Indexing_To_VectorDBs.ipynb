{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4658481a-f484-4d44-a742-52504306561a",
      "metadata": {
        "id": "4658481a-f484-4d44-a742-52504306561a"
      },
      "source": [
        "# Rag From Scratch: Indexing\n",
        "\n",
        "![Screenshot 2024-03-25 at 8.23.02 PM.png](indexing.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "095c203b",
      "metadata": {
        "id": "095c203b"
      },
      "source": [
        "## Set Environment Vars and API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "96d81ac8",
      "metadata": {
        "id": "96d81ac8"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'advanced-rag'\n",
        "os.environ['LANGCHAIN_API_KEY'] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c574333e-6a0d-4f4e-8897-783cd71bdcc2",
      "metadata": {
        "id": "c574333e-6a0d-4f4e-8897-783cd71bdcc2"
      },
      "source": [
        "## Part 12: Multi-representation Indexing\n",
        "\n",
        "Flow:\n",
        "\n",
        " ![Screenshot 2024-03-16 at 5.54.55 PM.png](multiindexing.png)\n",
        "\n",
        "Docs:\n",
        "\n",
        "https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9314f037",
      "metadata": {},
      "source": [
        "- đọc 2 bài trên 2 trang web để làm docs\n",
        "- thực hiện tóm tắt 2 bài\n",
        "- lưu trữ vào không gian chromaDB, docs sẽ được ánh xạ đến một doc_id và được embedding thông qua hf_embeddings\n",
        "- tìm kiếm bằng similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf368e7-ebf6-4469-bfa7-62466184afbb",
      "metadata": {
        "id": "1bf368e7-ebf6-4469-bfa7-62466184afbb"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://medium.com/@pankaj_pandey/introduction-to-retrieval-augmented-generation-rag-9209bf8a076d\")\n",
        "docs = loader.load()\n",
        "\n",
        "loader = WebBaseLoader(\"https://medium.com/humansdotai/an-introduction-to-ai-agents-e8c4afd2ee8f\")\n",
        "docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9376ba4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install langchain beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "432ac8f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://cloud.google.com/use-cases/retrieval-augmented-generation\")\n",
        "docs = loader.load()\n",
        "\n",
        "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Retrieval-augmented_generation\")\n",
        "docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a9e8ca01",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(metadata={'source': 'https://cloud.google.com/use-cases/retrieval-augmented-generation', 'title': 'What is Retrieval-Augmented Generation (RAG)? | Google Cloud', 'description': 'Retrieval-augmented generation (RAG) combines LLMs with external knowledge bases to improve their outputs. Learn more with Google Cloud.', 'language': 'en-US'}, page_content='What is Retrieval-Augmented Generation (RAG)? | Google CloudPage ContentsTopicsRAGWhat is Retrieval-Augmented Generation (RAG)?RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as search and databases) with the capabilities of generative large language models (LLMs). By combining your data and world knowledge with LLM language skills, grounded generation is more accurate, up-to-date, and relevant to your specific needs. Check out this e-book to unlock your “Enterprise Truth.”Get started for free35:30Grounding for Gemini with Vertex AI Search and DIY RAGHow does Retrieval-Augmented Generation work?RAGs operate with a few main steps to help enhance generative AI outputs:\\xa0Retrieval and pre-processing: RAGs leverage powerful search algorithms to query external data, such as web pages, knowledge bases, and databases. Once retrieved, the relevant information undergoes pre-processing, including tokenization, stemming, and removal of stop words.Grounded generation: The pre-processed retrieved information is then seamlessly incorporated into the pre-trained LLM. This integration enhances the LLM\\'s context, providing it with a more comprehensive understanding of the topic. This augmented context enables the LLM to generate more precise, informative, and engaging responses.\\xa0Why Use RAG?RAG offers several advantages augmenting traditional methods of text generation, especially when dealing with factual information or data-driven responses. Here are some key reasons why using RAG can be beneficial:Access to fresh informationLLMs are limited to their pre-trained data. This leads to outdated and potentially inaccurate responses. RAG overcomes this by providing up-to-date information to\\xa0LLMs.Factual groundingLLMs are powerful tools for generating creative and engaging text, but they can sometimes struggle with factual accuracy. This is because LLMs are trained on massive amounts of text data, which may contain inaccuracies or biases.Providing “facts” to the LLM as part of the input prompt can mitigate “gen AI hallucinations.”\\xa0The crux of this approach is ensuring that the most relevant facts are provided to the LLM, and that the LLM output is entirely grounded on those facts while also answering the user’s question and adhering to system instructions and safety constraints.Using Gemini’s long context window (LCW) is a great way to provide source materials to the LLM.\\xa0If you need to provide more information than fits into the LCW, or if you need to scale up performance, you can use a RAG approach that will reduce the number of tokens, saving you time and cost.Search with vector databases and relevancy re-rankersRAGs usually retrieve facts via search, and modern search engines now leverage vector databases to efficiently retrieve relevant documents. Vector databases store documents as embeddings in a high-dimensional space, allowing for fast and accurate retrieval based on semantic similarity.\\xa0Multi-modal embeddings can be used for images, audio and video, and more and these media embeddings can be retrieved alongside text embeddings or multi-language embeddings.Advanced search engines like Vertex AI Search use semantic search and keyword search together (called hybrid search), and a re-ranker which scores search results to ensure the top returned results are the most relevant.\\xa0Additionally searches perform better with a clear, focused query without misspellings; so prior to lookup, sophisticated search engines will transform a query and fix spelling mistakes.Relevance, accuracy, and qualityThe retrieval mechanism in RAG is critically important.\\xa0You need the best semantic search on top of a curated knowledge base to ensure that the retrieved information is relevant to the input query or context.\\xa0If your retrieved information is irrelevant, your generation could be grounded but off-topic or incorrect.By fine-tuning or prompt-engineering the LLM to generate text entirely based on the retrieved knowledge, RAG helps to minimize contradictions and inconsistencies in the generated text.\\xa0This significantly improves the quality of the generated text, and improves the user experience.The Vertex Eval Service now scores LLM generated text and retrieved chunks on metrics like “coherence,” “fluency,” “groundedness,” \"safety,\" “instruction_following,” “question_answering_quality,” and more.\\xa0These metrics help you measure the grounded text you get from the LLM (for some metrics that is a comparison to a ground truth answer you have provided).\\xa0Implementing these evaluations gives you a baseline measurement and you can optimize for RAG quality by configuring your search engine, curating your source data, improving source layout parsing or chunking strategies, or refining the user’s question prior to search.\\xa0A RAG Ops, metrics driven approach like this will help you hill climb to high quality RAG and grounded generation.RAGs, agents, and chatbotsRAG and grounding can be integrated into any LLM application or agent which needs access to fresh, private, or specialized data. By accessing external information, RAG-powered chatbots and conversational agents leverage external knowledge to provide more comprehensive, informative, and context-aware responses, improving the overall user experience.Your data and your use case are what differentiate what you are building with gen AI.\\xa0RAG and grounding bring your data to LLMs efficiently and scalably.What Google Cloud products and services are related to RAG?The following Google Cloud products are related to Retrieval-Augmented Generation:Vertex AI SearchVertex AI Search is Google Search for your data, a fully managed, out-of-the-box search and RAG builder.Vertex AI Vector SearchThe ultra performant vector index that powers Vertex AI Search; it enables semantic and hybrid search and retrieval from huge collections of embeddings with high recall at high query rate.BigQueryLarge datasets that you can use to train machine learning models, including models for Vertex AI Vector Search.Grounded Generation APIGemini high-fidelity mode grounded with Google Search or inline facts or bring your own search engine.AlloyDBRun models in Vertex AI and access them in your application using familiar SQL queries. Use Google models, such as Gemini, or your own custom models.LlamaIndex on VertexBuild your own search engine for RAG and grounding using Google or open source components and our fully managed orchestration system based on LlamaIndex.Further readingLearn more about using retrieval augmented generation with these resources.Using Vertex AI to build next-gen search applicationsRAGs powered by Google Search technologyRAG with databases on Google CloudAPIs to build your own search and Retrieval Augmented Generation (RAG) systemsHow to use RAG in BigQuery to bolster LLMsCode sample and quickstart to get familiar with RAGInfrastructure for a RAG-capable generative AI application using Vertex AI and Vector Search\\xa0Infrastructure for a RAG-capable generative AI application using Vertex AI and AlloyDB for PostgreSQLInfrastructure for a RAG-capable generative AI application using GKE\\xa0Take the next stepStart building on Google Cloud with $300 in free credits and 20+ always free products.Get started for freeNeed help getting started?Contact salesWork with a trusted partnerFind a partnerContinue browsingSee all productsmenuOverviewSolutionsProductsPricingResourcesDocsSupportContact Us\\ue8b6search_sparksend_sparkDocsSupportConsoleSign inStart freeStart freeContact UscloseAccelerate your digital transformationWhether your business is early in its journey or well on its way to digital transformation, Google Cloud can help solve your toughest challenges.Learn moreKey benefitsWhy Google CloudTop reasons businesses choose us.AI and MLGet enterprise-ready AI.MulticloudRun your apps wherever you need them.Global infrastructureBuild on the same infrastructure as Google.Data CloudMake smarter decisions with unified data.Modern Infrastructure CloudNext generation of cloud infrastructure.SecurityProtect your users, data, and apps.Productivity and collaborationConnect your teams with AI-powered apps.Reports and insightsExecutive insightsCurated C-suite perspectives.Analyst reportsRead what industry analysts say about us.WhitepapersBrowse and download popular whitepapers.Customer storiesExplore case studies and videos.closeIndustry SolutionsApplication ModernizationArtificial IntelligenceAPIs and ApplicationsData AnalyticsDatabasesInfrastructure ModernizationProductivity and CollaborationSecurityStartups and SMBSee all solutionsIndustry SolutionsReduce cost, increase operational agility, and capture new market opportunities.RetailAnalytics and collaboration tools for the retail value chain.Consumer Packaged GoodsSolutions for CPG digital transformation and brand growth.Financial ServicesComputing, data management, and analytics tools for financial services.Healthcare and Life SciencesAdvance research at scale and empower healthcare innovation.Media and EntertainmentSolutions for content production and distribution operations.TelecommunicationsHybrid and multi-cloud services to deploy and monetize 5G.GamesAI-driven solutions to build and scale games faster.ManufacturingMigration and AI tools to optimize the manufacturing value chain.Supply Chain and LogisticsEnable sustainable, efficient, and resilient data-driven operations across supply chain and logistics operations.GovernmentData storage, AI, and analytics solutions for government agencies.EducationTeaching tools to provide more engaging learning experiences.Not seeing what you\\'re looking for?See all industry solutionsApplication ModernizationAssess, plan, implement, and measure software practices and capabilities to modernize and simplify your organization’s business application portfolios.CAMPProgram that uses DORA to improve your software delivery capabilities.Modernize Traditional ApplicationsAnalyze, categorize, and get started with cloud migration on traditional workloads.Migrate from PaaS: Cloud Foundry, OpenshiftTools for moving your existing containers into Google\\'s managed container services.Migrate from MainframeAutomated tools and prescriptive guidance for moving your mainframe apps to the cloud.Modernize Software DeliverySoftware supply chain best practices - innerloop productivity, CI/CD and S3C.DevOps Best PracticesProcesses and resources for implementing DevOps in your org.SRE PrinciplesTools and resources for adopting SRE in your org.Day 2 Operations for GKETools and guidance for effective GKE management and monitoring.FinOps and Optimization of GKEBest practices for running reliable, performant, and cost effective applications on GKE.Run Applications at the EdgeGuidance for localized and low latency apps on Google’s hardware agnostic edge solution.Architect for MulticloudManage workloads across multiple clouds with a consistent platform.Go ServerlessFully managed environment for developing, deploying and scaling apps.Artificial IntelligenceAdd intelligence and efficiency to your business with AI and machine learning.Customer Engagement Suite with Google AIEnd-to-end application that combines our most advanced conversational AI.Document AIDocument processing and data capture automated at scale.Vertex AI Search for retailGoogle-quality search and product recommendations for retailers.Gemini for Google CloudAI assistants for application development, coding, and more.Generative AI on Google CloudTransform content creation and discovery, research, customer service, and developer efficiency with the power of generative AI.APIs and ApplicationsSpeed up the pace of innovation without coding, using APIs, apps, and automation.New Business Channels Using APIsAttract and empower an ecosystem of developers and partners.Unlocking Legacy Applications Using APIsCloud services for extending and modernizing legacy apps.Open Banking APIxSimplify and accelerate secure delivery of open banking compliant APIs.Data AnalyticsGenerate instant insights from data at any scale with a serverless, fully managed analytics platform that significantly simplifies analytics.Data MigrationMigrate and modernize with an AI-ready data platform.Data Lake ModernizationServices for building and modernizing your data lake.Stream AnalyticsInsights from ingesting, processing, and analyzing event streams.Marketing AnalyticsSolutions for collecting, analyzing, and activating customer data.DatasetsData from Google, public, and commercial providers to enrich your analytics and AI initiatives.Business IntelligenceSolutions for modernizing your BI stack and creating rich data experiences.AI for Data AnalyticsWrite SQL, build predictive models, and visualize data with AI for data analytics.DatabasesMigrate and manage enterprise data with security, reliability, high availability, and fully managed data services.Database MigrationGuides and tools to simplify your database migration life cycle.Database ModernizationUpgrades to modernize your operational database infrastructure.Databases for GamesBuild global, live games with Google Cloud databases.Google Cloud DatabasesDatabase services to migrate, manage, and modernize data.Migrate Oracle workloads to Google CloudRehost, replatform, rewrite your Oracle workloads.Open Source DatabasesFully managed open source databases with enterprise-grade support.SQL Server on Google CloudOptions for running SQL Server virtual machines on Google Cloud.Gemini for DatabasesSupercharge database development and management with AI.Infrastructure ModernizationMigrate quickly with solutions for SAP, VMware, Windows, Oracle, and other workloads.Application MigrationDiscovery and analysis tools for moving to the cloud.SAP on Google CloudCertifications for running SAP applications and SAP HANA.High Performance ComputingCompute, storage, and networking options to support any workload.Windows on Google CloudTools and partners for running Windows workloads.Data Center MigrationMigration solutions for VMs, apps, databases, and more.Active AssistAutomatic cloud resource optimization and increased security.Virtual DesktopsRemote work solutions for desktops and applications (VDI & DaaS).Rapid Migration and Modernization ProgramEnd-to-end migration program to simplify your path to the cloud.Backup and Disaster RecoveryEnsure your business continuity needs are met.Red Hat on Google CloudGoogle and Red Hat provide an enterprise-grade platform for traditional on-prem and custom applications.Cross-Cloud NetworkSimplify hybrid and multicloud networking, and secure your workloads, data, and users.ObservabilityMonitor, troubleshoot, and improve app performance with end-to-end visibility.Productivity and CollaborationChange the way teams work with solutions designed for humans and built for impact.Google WorkspaceCollaboration and productivity tools for enterprises.Google Workspace EssentialsSecure video meetings and modern collaboration for teams.Cloud IdentityUnified platform for IT admins to manage user devices and apps.Chrome EnterpriseChromeOS, Chrome Browser, and Chrome devices built for business.SecurityDetect, investigate, and respond to online threats to help protect your business.Security Analytics and OperationsSolution for analyzing petabytes of security telemetry.Web App and API ProtectionThreat and fraud protection for your web applications and APIs.Security and Resilience FrameworkSolutions for each phase of the security and resilience life cycle.Risk and compliance as code (RCaC)Solution to modernize your governance, risk, and compliance function with automation.Software Supply Chain SecuritySolution for improving end-to-end software supply chain security.Security FoundationRecommended products to help achieve a strong security posture.Google Cloud Cybershield™Strengthen nationwide cyber defense.Startups and SMBAccelerate startup and SMB growth with tailored solutions and programs.Startup ProgramGet financial, business, and technical support to take your startup to the next level.Small and Medium BusinessExplore solutions for web hosting, app development, AI, and analytics.Software as a ServiceBuild better SaaS products, scale efficiently, and grow your business.closeFeatured ProductsAI and Machine LearningBusiness IntelligenceComputeContainersData AnalyticsDatabasesDeveloper ToolsDistributed CloudHybrid and MulticloudIndustry SpecificIntegration ServicesManagement ToolsMaps and GeospatialMedia ServicesMigrationMixed RealityNetworkingOperationsProductivity and CollaborationSecurity and IdentityServerlessStorageWeb3See all products (100+)Featured ProductsCompute EngineVirtual machines running in Google’s data center.Cloud StorageObject storage that’s secure, durable, and scalable.BigQueryData warehouse for business agility and insights.Cloud RunFully managed environment for running containerized apps.Google Kubernetes EngineManaged environment for running containerized apps.Vertex AIUnified platform for ML models and generative AI.LookerPlatform for BI, data applications, and embedded analytics.Apigee API ManagementManage the full life cycle of APIs anywhere with visibility and control.Cloud SQLRelational database services for MySQL, PostgreSQL and SQL Server.GeminiGoogle Cloud products powered by Gemini.Cloud CDNContent delivery network for delivering web and video.Not seeing what you\\'re looking for?See all products (100+)AI and Machine LearningVertex AI PlatformUnified platform for ML models and generative AI.Vertex AI StudioBuild, tune, and deploy foundation models on Vertex AI.Vertex AI Agent BuilderBuild and deploy gen AI experiences.Conversational AgentsBuild conversational AI with both deterministic and gen AI functionality.Vertex AI SearchBuild Google-quality search for your enterprise apps and experiences.Speech-to-TextSpeech recognition and transcription across 125 languages.Text-to-SpeechSpeech synthesis in 220+ voices and 40+ languages.Translation AILanguage detection, translation, and glossary support.Document AIDocument processing and data capture automated at scale.Vision AICustom and pre-trained models to detect emotion, text, and more.Contact Center as a ServiceOmnichannel contact center solution that is native to the cloud.Not seeing what you\\'re looking for?See all AI and machine learning productsBusiness IntelligenceLookerPlatform for BI, data applications, and embedded analytics.Looker StudioInteractive data suite for dashboarding, reporting, and analytics.ComputeCompute EngineVirtual machines running in Google’s data center.App EngineServerless application platform for apps and back ends.Cloud GPUsGPUs for ML, scientific computing, and 3D visualization.Migrate to Virtual MachinesServer and virtual machine migration to Compute Engine.Spot VMsCompute instances for batch jobs and fault-tolerant workloads.BatchFully managed service for scheduling batch jobs.Sole-Tenant NodesDedicated hardware for compliance, licensing, and management.Bare MetalInfrastructure to run specialized workloads on Google Cloud.RecommenderUsage recommendations for Google Cloud products and services.VMware EngineFully managed, native VMware Cloud Foundation software stack.Cloud RunFully managed environment for running containerized apps.Not seeing what you\\'re looking for?See all compute productsContainersGoogle Kubernetes EngineManaged environment for running containerized apps.Cloud RunFully managed environment for running containerized apps.Cloud BuildSolution for running build steps in a Docker container.Artifact RegistryPackage manager for build artifacts and dependencies.Cloud CodeIDE support to write, run, and debug Kubernetes applications.Cloud DeployFully managed continuous delivery to GKE and Cloud Run.Migrate to ContainersComponents for migrating VMs into system containers on GKE.Deep Learning ContainersContainers with data science frameworks, libraries, and tools.KnativeComponents to create Kubernetes-native cloud-based software.Data AnalyticsBigQueryData warehouse for business agility and insights.LookerPlatform for BI, data applications, and embedded analytics.DataflowStreaming analytics for stream and batch processing.Pub/SubMessaging service for event ingestion and delivery.DataprocService for running Apache Spark and Apache Hadoop clusters.Cloud Data FusionData integration for building and managing data pipelines.Cloud ComposerWorkflow orchestration service built on Apache Airflow.BigLakeStorage engine to query multi-format and multimodal data.DataplexIntelligent data fabric for unifying data management across silos.DataformBuild, version control, and deploy SQL workflows in BigQuery.Analytics HubService for securely and efficiently exchanging data analytics assets.Not seeing what you\\'re looking for?See all data analytics productsDatabasesAlloyDB for PostgreSQLFully managed, PostgreSQL-compatible database for enterprise workloads.Cloud SQLFully managed database for MySQL, PostgreSQL, and SQL Server.FirestoreCloud-native document database for building rich mobile, web, and IoT apps.SpannerCloud-native relational database with unlimited scale and 99.999% availability.BigtableCloud-native wide-column database for large-scale, low-latency workloads.DatastreamServerless change data capture and replication service.Database Migration ServiceServerless, minimal downtime migrations to Cloud SQL.Bare Metal SolutionFully managed infrastructure for your Oracle workloads.MemorystoreFully managed Redis and Memcached for sub-millisecond data access.Developer ToolsArtifact RegistryUniversal package manager for build artifacts and dependencies.Cloud CodeIDE support to write, run, and debug Kubernetes applications.Cloud BuildContinuous integration and continuous delivery platform.Cloud DeployFully managed continuous delivery to GKE and Cloud Run.Cloud Deployment ManagerService for creating and managing Google Cloud resources.Cloud SDKCommand-line tools and libraries for Google Cloud.Cloud SchedulerCron job scheduler for task automation and management.Cloud Source RepositoriesPrivate Git repository to store, manage, and track code.Infrastructure ManagerAutomate infrastructure management with Terraform.Cloud WorkstationsManaged and secure development environments in the cloud.Gemini Code AssistAI-powered assistant available across Google Cloud and your IDE.Not seeing what you\\'re looking for?See all developer toolsDistributed CloudGoogle Distributed Cloud ConnectedDistributed cloud services for edge workloads.Google Distributed Cloud Air-gappedDistributed cloud for air-gapped workloads.Hybrid and MulticloudGoogle Kubernetes EngineManaged environment for running containerized apps.Apigee API ManagementAPI management, development, and security platform.Migrate to ContainersTool to move workloads and existing applications to GKE.Cloud BuildService for executing builds on Google Cloud infrastructure.ObservabilityMonitoring, logging, and application performance suite.Cloud Service MeshFully managed service mesh based on Envoy and Istio.Google Distributed CloudFully managed solutions for the edge and data centers.Industry SpecificAnti Money Laundering AIDetect suspicious, potential money laundering activity with AI.Cloud Healthcare APISolution for bridging existing care systems and apps on Google Cloud.Device Connect for FitbitGain a 360-degree patient view with connected Fitbit data on Google Cloud.Telecom Network AutomationReady to use cloud-native automation for telecom networks.Telecom Data FabricTelecom data management and analytics with an automated approach.Telecom Subscriber InsightsIngests data to improve subscriber acquisition and retention.Spectrum Access System (SAS)Controls fundamental access to the Citizens Broadband Radio Service (CBRS).Integration ServicesApplication IntegrationConnect to 3rd party apps and enable data consistency without code.WorkflowsWorkflow orchestration for serverless products and API services.Apigee API ManagementManage the full life cycle of APIs anywhere with visibility and control.Cloud TasksTask management service for asynchronous task execution.Cloud SchedulerCron job scheduler for task automation and management.DataprocService for running Apache Spark and Apache Hadoop clusters.Cloud Data FusionData integration for building and managing data pipelines.Cloud ComposerWorkflow orchestration service built on Apache Airflow.Pub/SubMessaging service for event ingestion and delivery.EventarcBuild an event-driven architecture that can connect any service.Management ToolsCloud ShellInteractive shell environment with a built-in command line.Cloud consoleWeb-based interface for managing and monitoring cloud apps.Cloud EndpointsDeployment and development management for APIs on Google Cloud.Cloud IAMPermissions management system for Google Cloud resources.Cloud APIsProgrammatic interfaces for  Google Cloud services.Service CatalogService catalog for admins managing internal enterprise solutions.Cost ManagementTools for monitoring, controlling, and optimizing your costs.ObservabilityMonitoring, logging, and application performance suite.Carbon FootprintDashboard to view and export Google Cloud carbon emissions reports.Config ConnectorKubernetes add-on for managing Google Cloud resources.Active AssistTools for easily managing performance, security, and cost.Not seeing what you\\'re looking for?See all management toolsMaps and GeospatialEarth EngineGeospatial platform for Earth observation data and analysis.Google Maps PlatformCreate immersive location experiences and improve business operations.Media ServicesCloud CDNContent delivery network for serving web and video content.Live Stream APIService to convert live video and package for streaming.OpenCueOpen source render manager for visual effects and animation.Transcoder APIConvert video files and package them for optimized delivery.Video Stitcher APIService for dynamic or server side ad insertion.MigrationMigration CenterUnified platform for migrating and modernizing with Google Cloud.Application MigrationApp migration to the cloud for low-cost refresh cycles.Migrate to Virtual MachinesComponents for migrating VMs and physical servers to Compute Engine.Cloud Foundation ToolkitReference templates for Deployment Manager and Terraform.Database Migration ServiceServerless, minimal downtime migrations to Cloud SQL.Migrate to ContainersComponents for migrating VMs into system containers on GKE.BigQuery Data Transfer ServiceData import service for scheduling and moving data into BigQuery.Rapid Migration and Modernization ProgramEnd-to-end migration program to simplify your path to the cloud.Transfer ApplianceStorage server for moving large volumes of data to Google Cloud.Storage Transfer ServiceData transfers from online and on-premises sources to Cloud Storage.VMware EngineMigrate and run your VMware workloads natively on Google Cloud.Mixed RealityImmersive Stream for XRHosts, renders, and streams 3D and XR experiences.NetworkingCloud ArmorSecurity policies and defense against web and DDoS attacks.Cloud CDN and Media CDNContent delivery network for serving web and video content.Cloud DNSDomain name system for reliable and low-latency name lookups.Cloud Load BalancingService for distributing traffic across applications and regions.Cloud NATNAT service for giving private instances internet access.Cloud ConnectivityConnectivity options for VPN, peering, and enterprise needs.Network Connectivity CenterConnectivity management to help simplify and scale networks.Network Intelligence CenterNetwork monitoring, verification, and optimization platform.Network Service TiersCloud network options  based on performance, availability, and cost.Virtual Private CloudSingle VPC for an entire organization, isolated within projects.Private Service ConnectSecure connection between your VPC and services.Not seeing what you\\'re looking for?See all networking productsOperationsCloud LoggingGoogle Cloud audit, platform, and application logs management.Cloud MonitoringInfrastructure and application health with rich metrics.Error ReportingApplication error identification and analysis.Managed Service for PrometheusFully-managed Prometheus on Google Cloud.Cloud TraceTracing system collecting latency data from applications.Cloud ProfilerCPU and heap profiler for analyzing application performance.Cloud QuotasManage quotas for all Google Cloud services.Productivity and CollaborationAppSheetNo-code development platform to build and extend applications.AppSheet AutomationBuild automations and applications on a unified platform.Google WorkspaceCollaboration and productivity tools for individuals and organizations.Google Workspace EssentialsSecure video meetings and modern collaboration for teams.Gemini for WorkspaceEmbeds generative AI across Google Workspace apps.Cloud IdentityUnified platform for IT admins to manage user devices and apps.Chrome EnterpriseChromeOS, Chrome browser, and Chrome devices built for business.Security and IdentityCloud IAMPermissions management system for Google Cloud resources.Sensitive Data ProtectionDiscover, classify, and protect your valuable data assets.Mandiant Managed DefenseFind and eliminate threats with confidence 24x7.Google Threat IntelligenceKnow who’s targeting you.Security Command CenterPlatform for defending against threats to your Google Cloud assets.Cloud Key ManagementManage encryption keys on Google Cloud.Mandiant Incident ResponseMinimize the impact of a breach.Chrome Enterprise PremiumGet secure enterprise browsing with extensive endpoint visibility.Assured WorkloadsCompliance and security controls for sensitive workloads.Google Security OperationsDetect, investigate, and respond to cyber threats.Mandiant ConsultingGet expert guidance before, during, and after an incident.Not seeing what you\\'re looking for?See all security and identity productsServerlessCloud RunFully managed environment for running containerized apps.Cloud FunctionsPlatform for creating functions that respond to cloud events.App EngineServerless application platform for apps and back ends.WorkflowsWorkflow orchestration for serverless products and API services.API GatewayDevelop, deploy, secure, and manage APIs with a fully managed gateway.StorageCloud StorageObject storage that’s secure, durable, and scalable.Block StorageHigh-performance storage for AI, analytics, databases, and enterprise applications.FilestoreFile storage that is highly scalable and secure.Persistent DiskBlock storage for virtual machine instances running on Google Cloud.Cloud Storage for FirebaseObject storage for storing and serving user-generated content.Local SSDBlock storage that is locally attached for high-performance needs.Storage Transfer ServiceData transfers from online and on-premises sources to Cloud Storage.ParallelstoreHigh performance, managed parallel file service.Google Cloud NetApp VolumesFile storage service for NFS, SMB, and multi-protocol environments.Backup and DR ServiceService for centralized, application-consistent data protection.Web3Blockchain Node EngineFully managed node hosting for developing on the blockchain.Blockchain RPCEnterprise-grade RPC for building on the blockchain.closeSave money with our transparent approach to pricingGoogle Cloud\\'s pay-as-you-go pricing offers automatic savings based on monthly usage and discounted rates for prepaid resources. Contact us today to get a quote.Request a quotePricing overview and toolsGoogle Cloud pricingPay only for what you use with no lock-in.Pricing calculatorCalculate your cloud savings.Google Cloud free tierExplore products with free monthly usage.Cost optimization frameworkGet best practices to optimize workload costs.Cost management toolsTools to monitor and control your costs.Product-specific PricingCompute EngineCloud SQLGoogle Kubernetes EngineCloud StorageBigQuerySee full price list with 100+ productscloseLearn & buildGoogle Cloud Free Program$300 in free credits and 20+ free products.Solution GeneratorGet AI generated solution recommendations.QuickstartsGet tutorials and walkthroughs.BlogRead our latest product news and stories.Learning HubGrow your career with role-based training.Google Cloud certificationPrepare and register for certifications.Cloud computing basicsLearn more about cloud computing basics.Cloud Architecture CenterGet reference architectures and best practices.ConnectInnovatorsJoin Google Cloud\\'s developer program.Developer CenterStay in the know and stay connected.Events and webinarsBrowse upcoming and on demand events.Google Cloud CommunityAsk questions, find answers, and connect.Consulting and PartnersGoogle Cloud ConsultingWork with our experts on cloud projects.Google Cloud MarketplaceDeploy ready-to-go solutions in a few clicks.Google Cloud partnersExplore benefits of working with a partner.Become a partnerJoin the Partner Advantage program.closeOverviewarrow_forwardSolutionsarrow_forwardProductsarrow_forwardPricingarrow_forwardResourcesarrow_forwardDocsSupportConsoleAccelerate your digital transformationLearn moreKey benefitsWhy Google CloudAI and MLMulticloudGlobal infrastructureData CloudModern Infrastructure CloudSecurityProductivity and collaborationReports and insightsExecutive insightsAnalyst reportsWhitepapersCustomer storiesIndustry SolutionsRetailConsumer Packaged GoodsFinancial ServicesHealthcare and Life SciencesMedia and EntertainmentTelecommunicationsGamesManufacturingSupply Chain and LogisticsGovernmentEducationSee all industry solutionsSee all solutionsApplication ModernizationCAMPModernize Traditional ApplicationsMigrate from PaaS: Cloud Foundry, OpenshiftMigrate from MainframeModernize Software DeliveryDevOps Best PracticesSRE PrinciplesDay 2 Operations for GKEFinOps and Optimization of GKERun Applications at the EdgeArchitect for MulticloudGo ServerlessArtificial IntelligenceCustomer Engagement Suite with Google AIDocument AIVertex AI Search for retailGemini for Google CloudGenerative AI on Google CloudAPIs and ApplicationsNew Business Channels Using APIsUnlocking Legacy Applications Using APIsOpen Banking APIxData AnalyticsData MigrationData Lake ModernizationStream AnalyticsMarketing AnalyticsDatasetsBusiness IntelligenceAI for Data AnalyticsDatabasesDatabase MigrationDatabase ModernizationDatabases for GamesGoogle Cloud DatabasesMigrate Oracle workloads to Google CloudOpen Source DatabasesSQL Server on Google CloudGemini for DatabasesInfrastructure ModernizationApplication MigrationSAP on Google CloudHigh Performance ComputingWindows on Google CloudData Center MigrationActive AssistVirtual DesktopsRapid Migration and Modernization ProgramBackup and Disaster RecoveryRed Hat on Google CloudCross-Cloud NetworkObservabilityProductivity and CollaborationGoogle WorkspaceGoogle Workspace EssentialsCloud IdentityChrome EnterpriseSecuritySecurity Analytics and OperationsWeb App and API ProtectionSecurity and Resilience FrameworkRisk and compliance as code (RCaC)Software Supply Chain SecuritySecurity FoundationGoogle Cloud Cybershield™Startups and SMBStartup ProgramSmall and Medium BusinessSoftware as a ServiceFeatured ProductsCompute EngineCloud StorageBigQueryCloud RunGoogle Kubernetes EngineVertex AILookerApigee API ManagementCloud SQLGeminiCloud CDNSee all products (100+)AI and Machine LearningVertex AI PlatformVertex AI StudioVertex AI Agent BuilderConversational AgentsVertex AI SearchSpeech-to-TextText-to-SpeechTranslation AIDocument AIVision AIContact Center as a ServiceSee all AI and machine learning productsBusiness IntelligenceLookerLooker StudioComputeCompute EngineApp EngineCloud GPUsMigrate to Virtual MachinesSpot VMsBatchSole-Tenant NodesBare MetalRecommenderVMware EngineCloud RunSee all compute productsContainersGoogle Kubernetes EngineCloud RunCloud BuildArtifact RegistryCloud CodeCloud DeployMigrate to ContainersDeep Learning ContainersKnativeData AnalyticsBigQueryLookerDataflowPub/SubDataprocCloud Data FusionCloud ComposerBigLakeDataplexDataformAnalytics HubSee all data analytics productsDatabasesAlloyDB for PostgreSQLCloud SQLFirestoreSpannerBigtableDatastreamDatabase Migration ServiceBare Metal SolutionMemorystoreDeveloper ToolsArtifact RegistryCloud CodeCloud BuildCloud DeployCloud Deployment ManagerCloud SDKCloud SchedulerCloud Source RepositoriesInfrastructure ManagerCloud WorkstationsGemini Code AssistSee all developer toolsDistributed CloudGoogle Distributed Cloud ConnectedGoogle Distributed Cloud Air-gappedHybrid and MulticloudGoogle Kubernetes EngineApigee API ManagementMigrate to ContainersCloud BuildObservabilityCloud Service MeshGoogle Distributed CloudIndustry SpecificAnti Money Laundering AICloud Healthcare APIDevice Connect for FitbitTelecom Network AutomationTelecom Data FabricTelecom Subscriber InsightsSpectrum Access System (SAS)Integration ServicesApplication IntegrationWorkflowsApigee API ManagementCloud TasksCloud SchedulerDataprocCloud Data FusionCloud ComposerPub/SubEventarcManagement ToolsCloud ShellCloud consoleCloud EndpointsCloud IAMCloud APIsService CatalogCost ManagementObservabilityCarbon FootprintConfig ConnectorActive AssistSee all management toolsMaps and GeospatialEarth EngineGoogle Maps PlatformMedia ServicesCloud CDNLive Stream APIOpenCueTranscoder APIVideo Stitcher APIMigrationMigration CenterApplication MigrationMigrate to Virtual MachinesCloud Foundation ToolkitDatabase Migration ServiceMigrate to ContainersBigQuery Data Transfer ServiceRapid Migration and Modernization ProgramTransfer ApplianceStorage Transfer ServiceVMware EngineMixed RealityImmersive Stream for XRNetworkingCloud ArmorCloud CDN and Media CDNCloud DNSCloud Load BalancingCloud NATCloud ConnectivityNetwork Connectivity CenterNetwork Intelligence CenterNetwork Service TiersVirtual Private CloudPrivate Service ConnectSee all networking productsOperationsCloud LoggingCloud MonitoringError ReportingManaged Service for PrometheusCloud TraceCloud ProfilerCloud QuotasProductivity and CollaborationAppSheetAppSheet AutomationGoogle WorkspaceGoogle Workspace EssentialsGemini for WorkspaceCloud IdentityChrome EnterpriseSecurity and IdentityCloud IAMSensitive Data ProtectionMandiant Managed DefenseGoogle Threat IntelligenceSecurity Command CenterCloud Key ManagementMandiant Incident ResponseChrome Enterprise PremiumAssured WorkloadsGoogle Security OperationsMandiant ConsultingSee all security and identity productsServerlessCloud RunCloud FunctionsApp EngineWorkflowsAPI GatewayStorageCloud StorageBlock StorageFilestorePersistent DiskCloud Storage for FirebaseLocal SSDStorage Transfer ServiceParallelstoreGoogle Cloud NetApp VolumesBackup and DR ServiceWeb3Blockchain Node EngineBlockchain RPCSave money with our transparent approach to pricingRequest a quotePricing overview and toolsGoogle Cloud pricingPricing calculatorGoogle Cloud free tierCost optimization frameworkCost management toolsProduct-specific PricingCompute EngineCloud SQLGoogle Kubernetes EngineCloud StorageBigQuerySee full price list with 100+ productsLearn & buildGoogle Cloud Free ProgramSolution GeneratorQuickstartsBlogLearning HubGoogle Cloud certificationCloud computing basicsCloud Architecture CenterConnectInnovatorsDeveloper CenterEvents and webinarsGoogle Cloud CommunityConsulting and PartnersGoogle Cloud ConsultingGoogle Cloud MarketplaceGoogle Cloud partnersBecome a partnerWhy GoogleChoosing Google CloudTrust and securityModern Infrastructure CloudMulticloudGlobal infrastructureCustomers and case studiesAnalyst reportsWhitepapersBlogProducts and pricingGoogle Cloud pricingGoogle Workspace pricingSee all productsSolutionsInfrastructure modernizationDatabasesApplication modernizationSmart analyticsArtificial IntelligenceSecurityProductivity & work transformationIndustry solutionsDevOps solutionsSmall business solutionsSee all solutionsResourcesGoogle Cloud Affiliate ProgramGoogle Cloud documentationGoogle Cloud quickstartsGoogle Cloud MarketplaceLearn about cloud computingSupportCode samplesCloud Architecture CenterTrainingCertificationsGoogle for DevelopersGoogle Cloud for StartupsSystem statusRelease NotesEngageContact salesFind a PartnerBecome a PartnerEventsPodcastsDeveloper CenterPress CornerGoogle Cloud on YouTubeGoogle Cloud Tech on YouTubeFollow on XJoin User ResearchWe\\'re hiring. Join Google Cloud!Google Cloud CommunityAbout GooglePrivacySite termsGoogle Cloud termsCookies management controlsOur third decade of climate action: join usSign up for the Google Cloud newsletterSubscribelanguage\\u202aEnglish\\u202c\\u202aEnglish\\u202c\\u202aDeutsch\\u202c\\u202aEspañol\\u202c\\u202aEspañol (Latinoamérica)\\u202c\\u202aFrançais\\u202c\\u202aIndonesia\\u202c\\u202aItaliano\\u202c\\u202aPortuguês (Brasil)\\u202c\\u202a简体中文\\u202c\\u202a繁體中文\\u202c\\u202a日本語\\u202c\\u202a한국어\\u202c'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nRetrieval-augmented generation - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nProcess\\n\\n\\n\\n\\nToggle Process subsection\\n\\n\\n\\n\\n\\n1.1\\nIndexing\\n\\n\\n\\n\\n\\n\\n\\n\\n1.2\\nRetrieval\\n\\n\\n\\n\\n\\n\\n\\n\\n1.3\\nAugmentation\\n\\n\\n\\n\\n\\n\\n\\n\\n1.4\\nGeneration\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nImprovements\\n\\n\\n\\n\\nToggle Improvements subsection\\n\\n\\n\\n\\n\\n2.1\\nEncoder\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nRetriever-centric methods\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nLanguage model\\n\\n\\n\\n\\n\\n\\n\\n\\n2.4\\nChunking\\n\\n\\n\\n\\n\\n\\n\\n\\n2.5\\nKnowledge Graphs\\n\\n\\n\\n\\n\\n\\n\\n\\n2.6\\nHybrid Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nChallenges\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nRetrieval-augmented generation\\n\\n\\n\\n5 languages\\n\\n\\n\\n\\nCatalàDeutsch한국어Українська中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nType of information retrieval using LLMs\\nRetrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.[1]  \\nUse cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.[2]\\n\\n\\nProcess[edit]\\nThe RAG process is made up of four key stages.[3] First, all the data must be prepared and indexed for use by the LLM. Thereafter, each query consists of a retrieval,[4] augmentation, and generation phase.[1]\\n\\nIndexing[edit]\\nTypically, the data to be referenced is converted into LLM embeddings, numerical representations in the form of large vectors. RAG can be used on unstructured (usually text), semi-structured, or structured data (for example knowledge graphs).[1] These embeddings are then stored in a vector database to allow for document retrieval.\\n\\nOverview of RAG process, combining external documents and user input into an LLM prompt to get tailored output\\nRetrieval[edit]\\nGiven a user query, a document retriever is first called to select the most relevant documents that will be used to augment the query.[5] This comparison can be done using a variety of methods, which depend in part on the type of indexing used.[1]\\n\\nAugmentation[edit]\\nThe model feeds this relevant retrieved information into the LLM via prompt engineering of the user\\'s original query.[2] Newer implementations (as of 2023[update]) can also incorporate specific augmentation modules with abilities such as expanding queries into multiple domains and using memory and self-improvement to learn from previous retrievals.[1]\\n\\nGeneration[edit]\\nFinally, the LLM can generate output based on both the query and the retrieved documents.[6] Some models incorporate extra steps to improve output, such as the re-ranking of retrieved information, context selection, and fine-tuning.[1]\\n\\nImprovements[edit]\\nImprovements to the basic process above can be applied at different stages in the RAG flow. \\n\\nEncoder[edit]\\nThese methods center around the encoding of text as either dense or sparse vectors. Sparse vectors, used to encode the identity of a word, are typically dictionary length and contain almost all zeros. Dense vectors, used to encode meaning, are much smaller and contain far fewer zeros. Several enhancements can be made to the way similarities are calculated in the vector stores (databases).  \\n\\nPerformance can be improved with faster dot products, approximate nearest neighbors, or centroid searches.[7]\\nAccuracy can be improved with Late Interactions.[clarification needed][8]\\nHybrid vectors: dense vector representations can be combined with sparse one-hot vectors in order to use the faster sparse dot products rather than the slower dense ones.[9]  Other[clarification needed] methods can combine sparse methods (BM25, SPLADE) with dense ones like DRAGON.\\nRetriever-centric methods[edit]\\nThese methods focus on improving the quality of hits from the vector database:\\n\\npre-train the retriever using the Inverse Cloze Task.[10]\\nprogressive data augmentation.  The method of Dragon samples difficult negatives to train a dense vector  retriever.[11]\\nUnder supervision, train the retriever for a given generator.  Given a prompt and the desired answer, retrieve the top-k vectors, and feed those vectors into the generator to achieve a perplexity score for the correct answer.  Then minimize the KL-divergence between the observed retrieved vectors probability and LM likelihoods to adjust the retriever.[12]\\nuse reranking to train the retriever.[13]\\n\\n\\nLanguage model[edit]\\n\\nRetro language model for RAG.  Each Retro block consists of Attention, Chunked Cross Attention, and Feed Forward layers.  Black-lettered boxes show data being changed, and blue lettering shows the algorithm performing the changes.\\nBy redesigning the language model with the retriever in mind, a 25-time smaller network can get comparable perplexity as its much larger counterparts.[14]  Because it is trained from scratch, this method (Retro) incurs the high cost of training runs that the original RAG scheme avoided.  The hypothesis is that by giving domain knowledge during training, Retro needs less focus on the domain and can devote its smaller weight resources only to language semantics.  The redesigned language model is shown here.  \\nIt has been reported that Retro is not reproducible, so modifications were made to make it so.  The more reproducible version is called Retro++ and includes in-context RAG.[15]\\n\\nChunking[edit]\\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\\xa0\"Retrieval-augmented generation\"\\xa0–\\xa0news\\xa0· newspapers\\xa0· books\\xa0· scholar\\xa0· JSTOR (October 2024) (Learn how and when to remove this message)\\nChunking involves various strategies for breaking up the data into vectors so the retriever can find details in it.\\n\\n\\nDifferent data styles have patterns that correct chunking can take advantage of.\\nThree types of chunking strategies are:\\n\\nFixed length with overlap. This is fast and easy.  Overlapping consecutive chunks helps to maintain semantic context across chunks.\\nSyntax-based chunks can break the document up into sentences.  Libraries such as spaCy or NLTK can also help.\\nFile format-based chunking. Certain file types have natural chunks built in, and it\\'s best to respect them.  For example, code files are best chunked and vectorized as whole functions or classes.  HTML files should leave <table> or base64 encoded <img> elements intact.  Similar considerations should be taken for pdf files.  Libraries such as Unstructured or Langchain can assist with this method.\\nKnowledge Graphs[edit]\\nRather than using documents as a source to vectorize and retrieve from, Knowledge Graphs can be used.  One can start with a set of documents, books, or other bodies of text, and convert them to a knowledge graph using one of many methods, including language models.  Once the knowledge graph is created, subgraphs can be vectorized, stored in a vector database, and used for retrieval as in plain RAG.  The advantage here is that graphs has more recognizable structure than strings of text and this structure can help retrieve more relevant facts for generation.  Sometimes this approach is called GraphRAG.\\n\\nHybrid Search[edit]\\nSometimes vector database searches can miss key facts needed to answer a user\\'s question.  One way to mitigate this is to do a traditional text search, add those results to the text chunks linked to the retrieved vectors from the vector search, and feed the combined hybrid text into the language model for generation.\\n\\nChallenges[edit]\\nIf the external data source is large, retrieval can be slow. The use of RAG does not completely eliminate the general challenges faced by LLMs, including hallucination.[5][16]\\n\\nReferences[edit]\\n\\n\\n^ a b c d e f Gao, Yunfan; Xiong, Yun; Gao, Xinyu; Jia, Kangxiang; Pan, Jinliu; Bi, Yuxi; Dai, Yi; Sun, Jiawei; Wang, Meng; Wang, Haofen (2023). \"Retrieval-Augmented Generation for Large Language Models: A Survey\". arXiv:2312.10997 [cs.CL].\\n\\n^ a b \"What is RAG? - Retrieval-Augmented Generation AI Explained - AWS\". Amazon Web Services, Inc. Retrieved 16 July 2024.\\n\\n^ \"What is Retrieval Augmented Generation?\". Roboflow Blog. 2023-11-16. Retrieved 2025-02-05.\\n\\n^ \"Evolving Interactions | Looking Glass 2024\". Thoughtworks. Retrieved 2024-12-12.\\n\\n^ a b \"Next-Gen Large Language Models: The Retrieval-Augmented Generation (RAG) Handbook\". freeCodeCamp.org. 11 June 2024. Retrieved 16 July 2024.\\n\\n^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459–9474. arXiv:2005.11401.\\n\\n^  \"faiss\". GitHub. \\n\\n^ Khattab, Omar; Zaharia, Matei (2020). \"\"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\"\". doi:10.1145/3397271.3401075. \\n\\n^ Formal, Thibault; Lassance, Carlos; Piwowarski, Benjamin; Clinchant, Stéphane (2021). \"\"SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval\"\". arXiv:2109.10086 [cs.IR]. \\n\\n^  Lee, Kenton; Chang, Ming-Wei; Toutanova, Kristina (2019). \"\"Latent Retrieval for Weakly Supervised Open Domain Question Answering\"\" (PDF). \\n\\n^ Lin, Sheng-Chieh; Asai, Akari (2023). \"\"How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval\"\" (PDF). \\n\\n^ Shi, Weijia; Min, Sewon (2024). \"REPLUG: Retrieval-Augmented Black-Box Language Models\". \"REPLUG: Retrieval-Augmented Black-Box Language Models\". pp.\\xa08371–8384. arXiv:2301.12652. doi:10.18653/v1/2024.naacl-long.463. \\n\\n^ Ram, Ori; Levine, Yoav; Dalmedigos, Itay; Muhlgay, Dor; Shashua, Amnon; Leyton-Brown, Kevin; Shoham, Yoav (2023). \"\"In-Context Retrieval-Augmented Language Models\"\". Transactions of the Association for Computational Linguistics. 11: 1316–1331. arXiv:2302.00083. doi:10.1162/tacl_a_00605. \\n\\n^ Borgeaud, Sebastian; Mensch, Arthur (2021). \"\"Improving language models by retrieving from trillions of tokens\"\" (PDF). \\n\\n^ Wang, Boxin; Ping, Wei (2023). \"\"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study\"\" (PDF). \\n\\n^ Magesh, Varun; Surani, Faiz; Dahl, Matthew; Suzgun, Mirac; Manning, Christopher D.; Ho, Daniel E. (2024-05-30). \"Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools\". arXiv:2405.20362 [cs.CL].\\n\\n\\nvteGenerative AIConcepts\\nAutoencoder\\nDeep learning\\nGenerative adversarial network\\nGenerative pre-trained transformer\\nLarge language model\\nNeural network\\nPrompt engineering\\nRetrieval-augmented generation\\nReinforcement learning from human feedback\\nSelf-supervised learning\\nTransformer\\nVariational autoencoder\\nVision transformer\\nWord embedding\\nModelsText\\nClaude\\nDBRX\\nGemini\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\nGrok\\nGranite\\nLlama\\nMistral Large\\nPanGu-Σ\\nQwen\\nImage\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nMidjourney\\nStable Diffusion\\nVideo\\nDream Machine\\nGen-3 Alpha\\nHailuo AI\\nKling\\nSora\\nVeo\\nVideoPoet\\nMusic\\nUdio\\nSuno AI\\nCompanies\\n01.AI\\nAlibaba\\nAnthropic\\nBaichuan\\nDeepSeek\\nElevenLabs\\nGoogle DeepMind\\nHugging Face\\nKuaishou\\nMeta AI\\nMiniMax\\nMistral AI\\nMoonshot AI\\nOpenAI\\nRunway\\nStability AI\\nSynthesia\\nxAI\\nZhipu AI\\n\\n Category\\n Commons\\n\\nvteArtificial intelligence (AI)History (timeline)Concepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nPolicy gradient\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nUncanny valley\\nRLHF\\nSelf-supervised learning\\nRecursive self-improvement\\nWord embedding\\nHallucination\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge language model\\nNMT\\nArtificial general intelligence\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nSpeech synthesis\\n15.ai\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nImagen\\nMidjourney\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nGen-3 Alpha\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\nClaude\\nGemini\\nchatbot\\nGrok\\nLaMDA\\nBLOOM\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDeepSeek\\nQwen\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nClaude Shannon\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nJürgen Schmidhuber\\nYann LeCun\\nGeoffrey Hinton\\nJohn Hopfield\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nDemis Hassabis\\nDavid Silver\\nIan Goodfellow\\nAndrej Karpathy\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)\\n\\n Portals\\nTechnology\\n Category\\nArtificial neural networks\\nMachine learning\\n List\\nCompanies\\nProjects\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Retrieval-augmented_generation&oldid=1274165718\"\\nCategories: Large language modelsNatural language processingInformation retrieval systemsGenerative artificial intelligenceHidden categories: Articles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2023All articles containing potentially dated statementsWikipedia articles needing clarification from August 2024Articles needing additional references from October 2024All articles needing additional references\\n\\n\\n\\n\\n\\n\\n This page was last edited on 5 February 2025, at 20:08\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nRetrieval-augmented generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]\n",
            "{'source': 'https://cloud.google.com/use-cases/retrieval-augmented-generation', 'title': 'What is Retrieval-Augmented Generation (RAG)? | Google Cloud', 'description': 'Retrieval-augmented generation (RAG) combines LLMs with external knowledge bases to improve their outputs. Learn more with Google Cloud.', 'language': 'en-US'}\n",
            "What is Retrieval-Augmented Generation (RAG)? | Google CloudPage ContentsTopicsRAGWhat is Retrieval-Augmented Generation (RAG)?RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as search and databases) with the capabilities of generative large language models (LLMs). By combining your data and world knowledge with LLM language skills, grounded generation is more accurate, up-to-date, and relevant to your specific needs. Check out this e-book to unlock your “Enterprise Truth.”Get started for free35:30Grounding for Gemini with Vertex AI Search and DIY RAGHow does Retrieval-Augmented Generation work?RAGs operate with a few main steps to help enhance generative AI outputs: Retrieval and pre-processing: RAGs leverage powerful search algorithms to query external data, such as web pages, knowledge bases, and databases. Once retrieved, the relevant information undergoes pre-processing, including tokenization, stemming, and removal of stop words.Grounded generation: The pre-processed retrieved information is then seamlessly incorporated into the pre-trained LLM. This integration enhances the LLM's context, providing it with a more comprehensive understanding of the topic. This augmented context enables the LLM to generate more precise, informative, and engaging responses. Why Use RAG?RAG offers several advantages augmenting traditional methods of text generation, especially when dealing with factual information or data-driven responses. Here are some key reasons why using RAG can be beneficial:Access to fresh informationLLMs are limited to their pre-trained data. This leads to outdated and potentially inaccurate responses. RAG overcomes this by providing up-to-date information to LLMs.Factual groundingLLMs are powerful tools for generating creative and engaging text, but they can sometimes struggle with factual accuracy. This is because LLMs are trained on massive amounts of text data, which may contain inaccuracies or biases.Providing “facts” to the LLM as part of the input prompt can mitigate “gen AI hallucinations.” The crux of this approach is ensuring that the most relevant facts are provided to the LLM, and that the LLM output is entirely grounded on those facts while also answering the user’s question and adhering to system instructions and safety constraints.Using Gemini’s long context window (LCW) is a great way to provide source materials to the LLM. If you need to provide more information than fits into the LCW, or if you need to scale up performance, you can use a RAG approach that will reduce the number of tokens, saving you time and cost.Search with vector databases and relevancy re-rankersRAGs usually retrieve facts via search, and modern search engines now leverage vector databases to efficiently retrieve relevant documents. Vector databases store documents as embeddings in a high-dimensional space, allowing for fast and accurate retrieval based on semantic similarity. Multi-modal embeddings can be used for images, audio and video, and more and these media embeddings can be retrieved alongside text embeddings or multi-language embeddings.Advanced search engines like Vertex AI Search use semantic search and keyword search together (called hybrid search), and a re-ranker which scores search results to ensure the top returned results are the most relevant. Additionally searches perform better with a clear, focused query without misspellings; so prior to lookup, sophisticated search engines will transform a query and fix spelling mistakes.Relevance, accuracy, and qualityThe retrieval mechanism in RAG is critically important. You need the best semantic search on top of a curated knowledge base to ensure that the retrieved information is relevant to the input query or context. If your retrieved information is irrelevant, your generation could be grounded but off-topic or incorrect.By fine-tuning or prompt-engineering the LLM to generate text entirely based on the retrieved knowledge, RAG helps to minimize contradictions and inconsistencies in the generated text. This significantly improves the quality of the generated text, and improves the user experience.The Vertex Eval Service now scores LLM generated text and retrieved chunks on metrics like “coherence,” “fluency,” “groundedness,” \"safety,\" “instruction_following,” “question_answering_quality,” and more. These metrics help you measure the grounded text you get from the LLM (for some metrics that is a comparison to a ground truth answer you have provided). Implementing these evaluations gives you a baseline measurement and you can optimize for RAG quality by configuring your search engine, curating your source data, improving source layout parsing or chunking strategies, or refining the user’s question prior to search. A RAG Ops, metrics driven approach like this will help you hill climb to high quality RAG and grounded generation.RAGs, agents, and chatbotsRAG and grounding can be integrated into any LLM application or agent which needs access to fresh, private, or specialized data. By accessing external information, RAG-powered chatbots and conversational agents leverage external knowledge to provide more comprehensive, informative, and context-aware responses, improving the overall user experience.Your data and your use case are what differentiate what you are building with gen AI. RAG and grounding bring your data to LLMs efficiently and scalably.What Google Cloud products and services are related to RAG?The following Google Cloud products are related to Retrieval-Augmented Generation:Vertex AI SearchVertex AI Search is Google Search for your data, a fully managed, out-of-the-box search and RAG builder.Vertex AI Vector SearchThe ultra performant vector index that powers Vertex AI Search; it enables semantic and hybrid search and retrieval from huge collections of embeddings with high recall at high query rate.BigQueryLarge datasets that you can use to train machine learning models, including models for Vertex AI Vector Search.Grounded Generation APIGemini high-fidelity mode grounded with Google Search or inline facts or bring your own search engine.AlloyDBRun models in Vertex AI and access them in your application using familiar SQL queries. Use Google models, such as Gemini, or your own custom models.LlamaIndex on VertexBuild your own search engine for RAG and grounding using Google or open source components and our fully managed orchestration system based on LlamaIndex.Further readingLearn more about using retrieval augmented generation with these resources.Using Vertex AI to build next-gen search applicationsRAGs powered by Google Search technologyRAG with databases on Google CloudAPIs to build your own search and Retrieval Augmented Generation (RAG) systemsHow to use RAG in BigQuery to bolster LLMsCode sample and quickstart to get familiar with RAGInfrastructure for a RAG-capable generative AI application using Vertex AI and Vector Search Infrastructure for a RAG-capable generative AI application using Vertex AI and AlloyDB for PostgreSQLInfrastructure for a RAG-capable generative AI application using GKE Take the next stepStart building on Google Cloud with $300 in free credits and 20+ always free products.Get started for freeNeed help getting started?Contact salesWork with a trusted partnerFind a partnerContinue browsingSee all productsmenuOverviewSolutionsProductsPricingResourcesDocsSupportContact Ussearch_sparksend_sparkDocsSupportConsoleSign inStart freeStart freeContact UscloseAccelerate your digital transformationWhether your business is early in its journey or well on its way to digital transformation, Google Cloud can help solve your toughest challenges.Learn moreKey benefitsWhy Google CloudTop reasons businesses choose us.AI and MLGet enterprise-ready AI.MulticloudRun your apps wherever you need them.Global infrastructureBuild on the same infrastructure as Google.Data CloudMake smarter decisions with unified data.Modern Infrastructure CloudNext generation of cloud infrastructure.SecurityProtect your users, data, and apps.Productivity and collaborationConnect your teams with AI-powered apps.Reports and insightsExecutive insightsCurated C-suite perspectives.Analyst reportsRead what industry analysts say about us.WhitepapersBrowse and download popular whitepapers.Customer storiesExplore case studies and videos.closeIndustry SolutionsApplication ModernizationArtificial IntelligenceAPIs and ApplicationsData AnalyticsDatabasesInfrastructure ModernizationProductivity and CollaborationSecurityStartups and SMBSee all solutionsIndustry SolutionsReduce cost, increase operational agility, and capture new market opportunities.RetailAnalytics and collaboration tools for the retail value chain.Consumer Packaged GoodsSolutions for CPG digital transformation and brand growth.Financial ServicesComputing, data management, and analytics tools for financial services.Healthcare and Life SciencesAdvance research at scale and empower healthcare innovation.Media and EntertainmentSolutions for content production and distribution operations.TelecommunicationsHybrid and multi-cloud services to deploy and monetize 5G.GamesAI-driven solutions to build and scale games faster.ManufacturingMigration and AI tools to optimize the manufacturing value chain.Supply Chain and LogisticsEnable sustainable, efficient, and resilient data-driven operations across supply chain and logistics operations.GovernmentData storage, AI, and analytics solutions for government agencies.EducationTeaching tools to provide more engaging learning experiences.Not seeing what you're looking for?See all industry solutionsApplication ModernizationAssess, plan, implement, and measure software practices and capabilities to modernize and simplify your organization’s business application portfolios.CAMPProgram that uses DORA to improve your software delivery capabilities.Modernize Traditional ApplicationsAnalyze, categorize, and get started with cloud migration on traditional workloads.Migrate from PaaS: Cloud Foundry, OpenshiftTools for moving your existing containers into Google's managed container services.Migrate from MainframeAutomated tools and prescriptive guidance for moving your mainframe apps to the cloud.Modernize Software DeliverySoftware supply chain best practices - innerloop productivity, CI/CD and S3C.DevOps Best PracticesProcesses and resources for implementing DevOps in your org.SRE PrinciplesTools and resources for adopting SRE in your org.Day 2 Operations for GKETools and guidance for effective GKE management and monitoring.FinOps and Optimization of GKEBest practices for running reliable, performant, and cost effective applications on GKE.Run Applications at the EdgeGuidance for localized and low latency apps on Google’s hardware agnostic edge solution.Architect for MulticloudManage workloads across multiple clouds with a consistent platform.Go ServerlessFully managed environment for developing, deploying and scaling apps.Artificial IntelligenceAdd intelligence and efficiency to your business with AI and machine learning.Customer Engagement Suite with Google AIEnd-to-end application that combines our most advanced conversational AI.Document AIDocument processing and data capture automated at scale.Vertex AI Search for retailGoogle-quality search and product recommendations for retailers.Gemini for Google CloudAI assistants for application development, coding, and more.Generative AI on Google CloudTransform content creation and discovery, research, customer service, and developer efficiency with the power of generative AI.APIs and ApplicationsSpeed up the pace of innovation without coding, using APIs, apps, and automation.New Business Channels Using APIsAttract and empower an ecosystem of developers and partners.Unlocking Legacy Applications Using APIsCloud services for extending and modernizing legacy apps.Open Banking APIxSimplify and accelerate secure delivery of open banking compliant APIs.Data AnalyticsGenerate instant insights from data at any scale with a serverless, fully managed analytics platform that significantly simplifies analytics.Data MigrationMigrate and modernize with an AI-ready data platform.Data Lake ModernizationServices for building and modernizing your data lake.Stream AnalyticsInsights from ingesting, processing, and analyzing event streams.Marketing AnalyticsSolutions for collecting, analyzing, and activating customer data.DatasetsData from Google, public, and commercial providers to enrich your analytics and AI initiatives.Business IntelligenceSolutions for modernizing your BI stack and creating rich data experiences.AI for Data AnalyticsWrite SQL, build predictive models, and visualize data with AI for data analytics.DatabasesMigrate and manage enterprise data with security, reliability, high availability, and fully managed data services.Database MigrationGuides and tools to simplify your database migration life cycle.Database ModernizationUpgrades to modernize your operational database infrastructure.Databases for GamesBuild global, live games with Google Cloud databases.Google Cloud DatabasesDatabase services to migrate, manage, and modernize data.Migrate Oracle workloads to Google CloudRehost, replatform, rewrite your Oracle workloads.Open Source DatabasesFully managed open source databases with enterprise-grade support.SQL Server on Google CloudOptions for running SQL Server virtual machines on Google Cloud.Gemini for DatabasesSupercharge database development and management with AI.Infrastructure ModernizationMigrate quickly with solutions for SAP, VMware, Windows, Oracle, and other workloads.Application MigrationDiscovery and analysis tools for moving to the cloud.SAP on Google CloudCertifications for running SAP applications and SAP HANA.High Performance ComputingCompute, storage, and networking options to support any workload.Windows on Google CloudTools and partners for running Windows workloads.Data Center MigrationMigration solutions for VMs, apps, databases, and more.Active AssistAutomatic cloud resource optimization and increased security.Virtual DesktopsRemote work solutions for desktops and applications (VDI & DaaS).Rapid Migration and Modernization ProgramEnd-to-end migration program to simplify your path to the cloud.Backup and Disaster RecoveryEnsure your business continuity needs are met.Red Hat on Google CloudGoogle and Red Hat provide an enterprise-grade platform for traditional on-prem and custom applications.Cross-Cloud NetworkSimplify hybrid and multicloud networking, and secure your workloads, data, and users.ObservabilityMonitor, troubleshoot, and improve app performance with end-to-end visibility.Productivity and CollaborationChange the way teams work with solutions designed for humans and built for impact.Google WorkspaceCollaboration and productivity tools for enterprises.Google Workspace EssentialsSecure video meetings and modern collaboration for teams.Cloud IdentityUnified platform for IT admins to manage user devices and apps.Chrome EnterpriseChromeOS, Chrome Browser, and Chrome devices built for business.SecurityDetect, investigate, and respond to online threats to help protect your business.Security Analytics and OperationsSolution for analyzing petabytes of security telemetry.Web App and API ProtectionThreat and fraud protection for your web applications and APIs.Security and Resilience FrameworkSolutions for each phase of the security and resilience life cycle.Risk and compliance as code (RCaC)Solution to modernize your governance, risk, and compliance function with automation.Software Supply Chain SecuritySolution for improving end-to-end software supply chain security.Security FoundationRecommended products to help achieve a strong security posture.Google Cloud Cybershield™Strengthen nationwide cyber defense.Startups and SMBAccelerate startup and SMB growth with tailored solutions and programs.Startup ProgramGet financial, business, and technical support to take your startup to the next level.Small and Medium BusinessExplore solutions for web hosting, app development, AI, and analytics.Software as a ServiceBuild better SaaS products, scale efficiently, and grow your business.closeFeatured ProductsAI and Machine LearningBusiness IntelligenceComputeContainersData AnalyticsDatabasesDeveloper ToolsDistributed CloudHybrid and MulticloudIndustry SpecificIntegration ServicesManagement ToolsMaps and GeospatialMedia ServicesMigrationMixed RealityNetworkingOperationsProductivity and CollaborationSecurity and IdentityServerlessStorageWeb3See all products (100+)Featured ProductsCompute EngineVirtual machines running in Google’s data center.Cloud StorageObject storage that’s secure, durable, and scalable.BigQueryData warehouse for business agility and insights.Cloud RunFully managed environment for running containerized apps.Google Kubernetes EngineManaged environment for running containerized apps.Vertex AIUnified platform for ML models and generative AI.LookerPlatform for BI, data applications, and embedded analytics.Apigee API ManagementManage the full life cycle of APIs anywhere with visibility and control.Cloud SQLRelational database services for MySQL, PostgreSQL and SQL Server.GeminiGoogle Cloud products powered by Gemini.Cloud CDNContent delivery network for delivering web and video.Not seeing what you're looking for?See all products (100+)AI and Machine LearningVertex AI PlatformUnified platform for ML models and generative AI.Vertex AI StudioBuild, tune, and deploy foundation models on Vertex AI.Vertex AI Agent BuilderBuild and deploy gen AI experiences.Conversational AgentsBuild conversational AI with both deterministic and gen AI functionality.Vertex AI SearchBuild Google-quality search for your enterprise apps and experiences.Speech-to-TextSpeech recognition and transcription across 125 languages.Text-to-SpeechSpeech synthesis in 220+ voices and 40+ languages.Translation AILanguage detection, translation, and glossary support.Document AIDocument processing and data capture automated at scale.Vision AICustom and pre-trained models to detect emotion, text, and more.Contact Center as a ServiceOmnichannel contact center solution that is native to the cloud.Not seeing what you're looking for?See all AI and machine learning productsBusiness IntelligenceLookerPlatform for BI, data applications, and embedded analytics.Looker StudioInteractive data suite for dashboarding, reporting, and analytics.ComputeCompute EngineVirtual machines running in Google’s data center.App EngineServerless application platform for apps and back ends.Cloud GPUsGPUs for ML, scientific computing, and 3D visualization.Migrate to Virtual MachinesServer and virtual machine migration to Compute Engine.Spot VMsCompute instances for batch jobs and fault-tolerant workloads.BatchFully managed service for scheduling batch jobs.Sole-Tenant NodesDedicated hardware for compliance, licensing, and management.Bare MetalInfrastructure to run specialized workloads on Google Cloud.RecommenderUsage recommendations for Google Cloud products and services.VMware EngineFully managed, native VMware Cloud Foundation software stack.Cloud RunFully managed environment for running containerized apps.Not seeing what you're looking for?See all compute productsContainersGoogle Kubernetes EngineManaged environment for running containerized apps.Cloud RunFully managed environment for running containerized apps.Cloud BuildSolution for running build steps in a Docker container.Artifact RegistryPackage manager for build artifacts and dependencies.Cloud CodeIDE support to write, run, and debug Kubernetes applications.Cloud DeployFully managed continuous delivery to GKE and Cloud Run.Migrate to ContainersComponents for migrating VMs into system containers on GKE.Deep Learning ContainersContainers with data science frameworks, libraries, and tools.KnativeComponents to create Kubernetes-native cloud-based software.Data AnalyticsBigQueryData warehouse for business agility and insights.LookerPlatform for BI, data applications, and embedded analytics.DataflowStreaming analytics for stream and batch processing.Pub/SubMessaging service for event ingestion and delivery.DataprocService for running Apache Spark and Apache Hadoop clusters.Cloud Data FusionData integration for building and managing data pipelines.Cloud ComposerWorkflow orchestration service built on Apache Airflow.BigLakeStorage engine to query multi-format and multimodal data.DataplexIntelligent data fabric for unifying data management across silos.DataformBuild, version control, and deploy SQL workflows in BigQuery.Analytics HubService for securely and efficiently exchanging data analytics assets.Not seeing what you're looking for?See all data analytics productsDatabasesAlloyDB for PostgreSQLFully managed, PostgreSQL-compatible database for enterprise workloads.Cloud SQLFully managed database for MySQL, PostgreSQL, and SQL Server.FirestoreCloud-native document database for building rich mobile, web, and IoT apps.SpannerCloud-native relational database with unlimited scale and 99.999% availability.BigtableCloud-native wide-column database for large-scale, low-latency workloads.DatastreamServerless change data capture and replication service.Database Migration ServiceServerless, minimal downtime migrations to Cloud SQL.Bare Metal SolutionFully managed infrastructure for your Oracle workloads.MemorystoreFully managed Redis and Memcached for sub-millisecond data access.Developer ToolsArtifact RegistryUniversal package manager for build artifacts and dependencies.Cloud CodeIDE support to write, run, and debug Kubernetes applications.Cloud BuildContinuous integration and continuous delivery platform.Cloud DeployFully managed continuous delivery to GKE and Cloud Run.Cloud Deployment ManagerService for creating and managing Google Cloud resources.Cloud SDKCommand-line tools and libraries for Google Cloud.Cloud SchedulerCron job scheduler for task automation and management.Cloud Source RepositoriesPrivate Git repository to store, manage, and track code.Infrastructure ManagerAutomate infrastructure management with Terraform.Cloud WorkstationsManaged and secure development environments in the cloud.Gemini Code AssistAI-powered assistant available across Google Cloud and your IDE.Not seeing what you're looking for?See all developer toolsDistributed CloudGoogle Distributed Cloud ConnectedDistributed cloud services for edge workloads.Google Distributed Cloud Air-gappedDistributed cloud for air-gapped workloads.Hybrid and MulticloudGoogle Kubernetes EngineManaged environment for running containerized apps.Apigee API ManagementAPI management, development, and security platform.Migrate to ContainersTool to move workloads and existing applications to GKE.Cloud BuildService for executing builds on Google Cloud infrastructure.ObservabilityMonitoring, logging, and application performance suite.Cloud Service MeshFully managed service mesh based on Envoy and Istio.Google Distributed CloudFully managed solutions for the edge and data centers.Industry SpecificAnti Money Laundering AIDetect suspicious, potential money laundering activity with AI.Cloud Healthcare APISolution for bridging existing care systems and apps on Google Cloud.Device Connect for FitbitGain a 360-degree patient view with connected Fitbit data on Google Cloud.Telecom Network AutomationReady to use cloud-native automation for telecom networks.Telecom Data FabricTelecom data management and analytics with an automated approach.Telecom Subscriber InsightsIngests data to improve subscriber acquisition and retention.Spectrum Access System (SAS)Controls fundamental access to the Citizens Broadband Radio Service (CBRS).Integration ServicesApplication IntegrationConnect to 3rd party apps and enable data consistency without code.WorkflowsWorkflow orchestration for serverless products and API services.Apigee API ManagementManage the full life cycle of APIs anywhere with visibility and control.Cloud TasksTask management service for asynchronous task execution.Cloud SchedulerCron job scheduler for task automation and management.DataprocService for running Apache Spark and Apache Hadoop clusters.Cloud Data FusionData integration for building and managing data pipelines.Cloud ComposerWorkflow orchestration service built on Apache Airflow.Pub/SubMessaging service for event ingestion and delivery.EventarcBuild an event-driven architecture that can connect any service.Management ToolsCloud ShellInteractive shell environment with a built-in command line.Cloud consoleWeb-based interface for managing and monitoring cloud apps.Cloud EndpointsDeployment and development management for APIs on Google Cloud.Cloud IAMPermissions management system for Google Cloud resources.Cloud APIsProgrammatic interfaces for  Google Cloud services.Service CatalogService catalog for admins managing internal enterprise solutions.Cost ManagementTools for monitoring, controlling, and optimizing your costs.ObservabilityMonitoring, logging, and application performance suite.Carbon FootprintDashboard to view and export Google Cloud carbon emissions reports.Config ConnectorKubernetes add-on for managing Google Cloud resources.Active AssistTools for easily managing performance, security, and cost.Not seeing what you're looking for?See all management toolsMaps and GeospatialEarth EngineGeospatial platform for Earth observation data and analysis.Google Maps PlatformCreate immersive location experiences and improve business operations.Media ServicesCloud CDNContent delivery network for serving web and video content.Live Stream APIService to convert live video and package for streaming.OpenCueOpen source render manager for visual effects and animation.Transcoder APIConvert video files and package them for optimized delivery.Video Stitcher APIService for dynamic or server side ad insertion.MigrationMigration CenterUnified platform for migrating and modernizing with Google Cloud.Application MigrationApp migration to the cloud for low-cost refresh cycles.Migrate to Virtual MachinesComponents for migrating VMs and physical servers to Compute Engine.Cloud Foundation ToolkitReference templates for Deployment Manager and Terraform.Database Migration ServiceServerless, minimal downtime migrations to Cloud SQL.Migrate to ContainersComponents for migrating VMs into system containers on GKE.BigQuery Data Transfer ServiceData import service for scheduling and moving data into BigQuery.Rapid Migration and Modernization ProgramEnd-to-end migration program to simplify your path to the cloud.Transfer ApplianceStorage server for moving large volumes of data to Google Cloud.Storage Transfer ServiceData transfers from online and on-premises sources to Cloud Storage.VMware EngineMigrate and run your VMware workloads natively on Google Cloud.Mixed RealityImmersive Stream for XRHosts, renders, and streams 3D and XR experiences.NetworkingCloud ArmorSecurity policies and defense against web and DDoS attacks.Cloud CDN and Media CDNContent delivery network for serving web and video content.Cloud DNSDomain name system for reliable and low-latency name lookups.Cloud Load BalancingService for distributing traffic across applications and regions.Cloud NATNAT service for giving private instances internet access.Cloud ConnectivityConnectivity options for VPN, peering, and enterprise needs.Network Connectivity CenterConnectivity management to help simplify and scale networks.Network Intelligence CenterNetwork monitoring, verification, and optimization platform.Network Service TiersCloud network options  based on performance, availability, and cost.Virtual Private CloudSingle VPC for an entire organization, isolated within projects.Private Service ConnectSecure connection between your VPC and services.Not seeing what you're looking for?See all networking productsOperationsCloud LoggingGoogle Cloud audit, platform, and application logs management.Cloud MonitoringInfrastructure and application health with rich metrics.Error ReportingApplication error identification and analysis.Managed Service for PrometheusFully-managed Prometheus on Google Cloud.Cloud TraceTracing system collecting latency data from applications.Cloud ProfilerCPU and heap profiler for analyzing application performance.Cloud QuotasManage quotas for all Google Cloud services.Productivity and CollaborationAppSheetNo-code development platform to build and extend applications.AppSheet AutomationBuild automations and applications on a unified platform.Google WorkspaceCollaboration and productivity tools for individuals and organizations.Google Workspace EssentialsSecure video meetings and modern collaboration for teams.Gemini for WorkspaceEmbeds generative AI across Google Workspace apps.Cloud IdentityUnified platform for IT admins to manage user devices and apps.Chrome EnterpriseChromeOS, Chrome browser, and Chrome devices built for business.Security and IdentityCloud IAMPermissions management system for Google Cloud resources.Sensitive Data ProtectionDiscover, classify, and protect your valuable data assets.Mandiant Managed DefenseFind and eliminate threats with confidence 24x7.Google Threat IntelligenceKnow who’s targeting you.Security Command CenterPlatform for defending against threats to your Google Cloud assets.Cloud Key ManagementManage encryption keys on Google Cloud.Mandiant Incident ResponseMinimize the impact of a breach.Chrome Enterprise PremiumGet secure enterprise browsing with extensive endpoint visibility.Assured WorkloadsCompliance and security controls for sensitive workloads.Google Security OperationsDetect, investigate, and respond to cyber threats.Mandiant ConsultingGet expert guidance before, during, and after an incident.Not seeing what you're looking for?See all security and identity productsServerlessCloud RunFully managed environment for running containerized apps.Cloud FunctionsPlatform for creating functions that respond to cloud events.App EngineServerless application platform for apps and back ends.WorkflowsWorkflow orchestration for serverless products and API services.API GatewayDevelop, deploy, secure, and manage APIs with a fully managed gateway.StorageCloud StorageObject storage that’s secure, durable, and scalable.Block StorageHigh-performance storage for AI, analytics, databases, and enterprise applications.FilestoreFile storage that is highly scalable and secure.Persistent DiskBlock storage for virtual machine instances running on Google Cloud.Cloud Storage for FirebaseObject storage for storing and serving user-generated content.Local SSDBlock storage that is locally attached for high-performance needs.Storage Transfer ServiceData transfers from online and on-premises sources to Cloud Storage.ParallelstoreHigh performance, managed parallel file service.Google Cloud NetApp VolumesFile storage service for NFS, SMB, and multi-protocol environments.Backup and DR ServiceService for centralized, application-consistent data protection.Web3Blockchain Node EngineFully managed node hosting for developing on the blockchain.Blockchain RPCEnterprise-grade RPC for building on the blockchain.closeSave money with our transparent approach to pricingGoogle Cloud's pay-as-you-go pricing offers automatic savings based on monthly usage and discounted rates for prepaid resources. Contact us today to get a quote.Request a quotePricing overview and toolsGoogle Cloud pricingPay only for what you use with no lock-in.Pricing calculatorCalculate your cloud savings.Google Cloud free tierExplore products with free monthly usage.Cost optimization frameworkGet best practices to optimize workload costs.Cost management toolsTools to monitor and control your costs.Product-specific PricingCompute EngineCloud SQLGoogle Kubernetes EngineCloud StorageBigQuerySee full price list with 100+ productscloseLearn & buildGoogle Cloud Free Program$300 in free credits and 20+ free products.Solution GeneratorGet AI generated solution recommendations.QuickstartsGet tutorials and walkthroughs.BlogRead our latest product news and stories.Learning HubGrow your career with role-based training.Google Cloud certificationPrepare and register for certifications.Cloud computing basicsLearn more about cloud computing basics.Cloud Architecture CenterGet reference architectures and best practices.ConnectInnovatorsJoin Google Cloud's developer program.Developer CenterStay in the know and stay connected.Events and webinarsBrowse upcoming and on demand events.Google Cloud CommunityAsk questions, find answers, and connect.Consulting and PartnersGoogle Cloud ConsultingWork with our experts on cloud projects.Google Cloud MarketplaceDeploy ready-to-go solutions in a few clicks.Google Cloud partnersExplore benefits of working with a partner.Become a partnerJoin the Partner Advantage program.closeOverviewarrow_forwardSolutionsarrow_forwardProductsarrow_forwardPricingarrow_forwardResourcesarrow_forwardDocsSupportConsoleAccelerate your digital transformationLearn moreKey benefitsWhy Google CloudAI and MLMulticloudGlobal infrastructureData CloudModern Infrastructure CloudSecurityProductivity and collaborationReports and insightsExecutive insightsAnalyst reportsWhitepapersCustomer storiesIndustry SolutionsRetailConsumer Packaged GoodsFinancial ServicesHealthcare and Life SciencesMedia and EntertainmentTelecommunicationsGamesManufacturingSupply Chain and LogisticsGovernmentEducationSee all industry solutionsSee all solutionsApplication ModernizationCAMPModernize Traditional ApplicationsMigrate from PaaS: Cloud Foundry, OpenshiftMigrate from MainframeModernize Software DeliveryDevOps Best PracticesSRE PrinciplesDay 2 Operations for GKEFinOps and Optimization of GKERun Applications at the EdgeArchitect for MulticloudGo ServerlessArtificial IntelligenceCustomer Engagement Suite with Google AIDocument AIVertex AI Search for retailGemini for Google CloudGenerative AI on Google CloudAPIs and ApplicationsNew Business Channels Using APIsUnlocking Legacy Applications Using APIsOpen Banking APIxData AnalyticsData MigrationData Lake ModernizationStream AnalyticsMarketing AnalyticsDatasetsBusiness IntelligenceAI for Data AnalyticsDatabasesDatabase MigrationDatabase ModernizationDatabases for GamesGoogle Cloud DatabasesMigrate Oracle workloads to Google CloudOpen Source DatabasesSQL Server on Google CloudGemini for DatabasesInfrastructure ModernizationApplication MigrationSAP on Google CloudHigh Performance ComputingWindows on Google CloudData Center MigrationActive AssistVirtual DesktopsRapid Migration and Modernization ProgramBackup and Disaster RecoveryRed Hat on Google CloudCross-Cloud NetworkObservabilityProductivity and CollaborationGoogle WorkspaceGoogle Workspace EssentialsCloud IdentityChrome EnterpriseSecuritySecurity Analytics and OperationsWeb App and API ProtectionSecurity and Resilience FrameworkRisk and compliance as code (RCaC)Software Supply Chain SecuritySecurity FoundationGoogle Cloud Cybershield™Startups and SMBStartup ProgramSmall and Medium BusinessSoftware as a ServiceFeatured ProductsCompute EngineCloud StorageBigQueryCloud RunGoogle Kubernetes EngineVertex AILookerApigee API ManagementCloud SQLGeminiCloud CDNSee all products (100+)AI and Machine LearningVertex AI PlatformVertex AI StudioVertex AI Agent BuilderConversational AgentsVertex AI SearchSpeech-to-TextText-to-SpeechTranslation AIDocument AIVision AIContact Center as a ServiceSee all AI and machine learning productsBusiness IntelligenceLookerLooker StudioComputeCompute EngineApp EngineCloud GPUsMigrate to Virtual MachinesSpot VMsBatchSole-Tenant NodesBare MetalRecommenderVMware EngineCloud RunSee all compute productsContainersGoogle Kubernetes EngineCloud RunCloud BuildArtifact RegistryCloud CodeCloud DeployMigrate to ContainersDeep Learning ContainersKnativeData AnalyticsBigQueryLookerDataflowPub/SubDataprocCloud Data FusionCloud ComposerBigLakeDataplexDataformAnalytics HubSee all data analytics productsDatabasesAlloyDB for PostgreSQLCloud SQLFirestoreSpannerBigtableDatastreamDatabase Migration ServiceBare Metal SolutionMemorystoreDeveloper ToolsArtifact RegistryCloud CodeCloud BuildCloud DeployCloud Deployment ManagerCloud SDKCloud SchedulerCloud Source RepositoriesInfrastructure ManagerCloud WorkstationsGemini Code AssistSee all developer toolsDistributed CloudGoogle Distributed Cloud ConnectedGoogle Distributed Cloud Air-gappedHybrid and MulticloudGoogle Kubernetes EngineApigee API ManagementMigrate to ContainersCloud BuildObservabilityCloud Service MeshGoogle Distributed CloudIndustry SpecificAnti Money Laundering AICloud Healthcare APIDevice Connect for FitbitTelecom Network AutomationTelecom Data FabricTelecom Subscriber InsightsSpectrum Access System (SAS)Integration ServicesApplication IntegrationWorkflowsApigee API ManagementCloud TasksCloud SchedulerDataprocCloud Data FusionCloud ComposerPub/SubEventarcManagement ToolsCloud ShellCloud consoleCloud EndpointsCloud IAMCloud APIsService CatalogCost ManagementObservabilityCarbon FootprintConfig ConnectorActive AssistSee all management toolsMaps and GeospatialEarth EngineGoogle Maps PlatformMedia ServicesCloud CDNLive Stream APIOpenCueTranscoder APIVideo Stitcher APIMigrationMigration CenterApplication MigrationMigrate to Virtual MachinesCloud Foundation ToolkitDatabase Migration ServiceMigrate to ContainersBigQuery Data Transfer ServiceRapid Migration and Modernization ProgramTransfer ApplianceStorage Transfer ServiceVMware EngineMixed RealityImmersive Stream for XRNetworkingCloud ArmorCloud CDN and Media CDNCloud DNSCloud Load BalancingCloud NATCloud ConnectivityNetwork Connectivity CenterNetwork Intelligence CenterNetwork Service TiersVirtual Private CloudPrivate Service ConnectSee all networking productsOperationsCloud LoggingCloud MonitoringError ReportingManaged Service for PrometheusCloud TraceCloud ProfilerCloud QuotasProductivity and CollaborationAppSheetAppSheet AutomationGoogle WorkspaceGoogle Workspace EssentialsGemini for WorkspaceCloud IdentityChrome EnterpriseSecurity and IdentityCloud IAMSensitive Data ProtectionMandiant Managed DefenseGoogle Threat IntelligenceSecurity Command CenterCloud Key ManagementMandiant Incident ResponseChrome Enterprise PremiumAssured WorkloadsGoogle Security OperationsMandiant ConsultingSee all security and identity productsServerlessCloud RunCloud FunctionsApp EngineWorkflowsAPI GatewayStorageCloud StorageBlock StorageFilestorePersistent DiskCloud Storage for FirebaseLocal SSDStorage Transfer ServiceParallelstoreGoogle Cloud NetApp VolumesBackup and DR ServiceWeb3Blockchain Node EngineBlockchain RPCSave money with our transparent approach to pricingRequest a quotePricing overview and toolsGoogle Cloud pricingPricing calculatorGoogle Cloud free tierCost optimization frameworkCost management toolsProduct-specific PricingCompute EngineCloud SQLGoogle Kubernetes EngineCloud StorageBigQuerySee full price list with 100+ productsLearn & buildGoogle Cloud Free ProgramSolution GeneratorQuickstartsBlogLearning HubGoogle Cloud certificationCloud computing basicsCloud Architecture CenterConnectInnovatorsDeveloper CenterEvents and webinarsGoogle Cloud CommunityConsulting and PartnersGoogle Cloud ConsultingGoogle Cloud MarketplaceGoogle Cloud partnersBecome a partnerWhy GoogleChoosing Google CloudTrust and securityModern Infrastructure CloudMulticloudGlobal infrastructureCustomers and case studiesAnalyst reportsWhitepapersBlogProducts and pricingGoogle Cloud pricingGoogle Workspace pricingSee all productsSolutionsInfrastructure modernizationDatabasesApplication modernizationSmart analyticsArtificial IntelligenceSecurityProductivity & work transformationIndustry solutionsDevOps solutionsSmall business solutionsSee all solutionsResourcesGoogle Cloud Affiliate ProgramGoogle Cloud documentationGoogle Cloud quickstartsGoogle Cloud MarketplaceLearn about cloud computingSupportCode samplesCloud Architecture CenterTrainingCertificationsGoogle for DevelopersGoogle Cloud for StartupsSystem statusRelease NotesEngageContact salesFind a PartnerBecome a PartnerEventsPodcastsDeveloper CenterPress CornerGoogle Cloud on YouTubeGoogle Cloud Tech on YouTubeFollow on XJoin User ResearchWe're hiring. Join Google Cloud!Google Cloud CommunityAbout GooglePrivacySite termsGoogle Cloud termsCookies management controlsOur third decade of climate action: join usSign up for the Google Cloud newsletterSubscribelanguage‪English‬‪English‬‪Deutsch‬‪Español‬‪Español (Latinoamérica)‬‪Français‬‪Indonesia‬‪Italiano‬‪Português (Brasil)‬‪简体中文‬‪繁體中文‬‪日本語‬‪한국어‬\n",
            "{'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Retrieval-augmented generation - Wikipedia\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jump to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\t\tNavigation\n",
            "\t\n",
            "\n",
            "\n",
            "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tContribute\n",
            "\t\n",
            "\n",
            "\n",
            "HelpLearn to editCommunity portalRecent changesUpload file\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Appearance\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Donate\n",
            "\n",
            "Create account\n",
            "\n",
            "Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Personal tools\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Donate Create account Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPages for logged out editors learn more\n",
            "\n",
            "\n",
            "\n",
            "ContributionsTalk\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Contents\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(Top)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1\n",
            "Process\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle Process subsection\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1.1\n",
            "Indexing\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1.2\n",
            "Retrieval\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1.3\n",
            "Augmentation\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1.4\n",
            "Generation\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2\n",
            "Improvements\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle Improvements subsection\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.1\n",
            "Encoder\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.2\n",
            "Retriever-centric methods\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.3\n",
            "Language model\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.4\n",
            "Chunking\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.5\n",
            "Knowledge Graphs\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "2.6\n",
            "Hybrid Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "3\n",
            "Challenges\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "4\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle the table of contents\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Retrieval-augmented generation\n",
            "\n",
            "\n",
            "\n",
            "5 languages\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CatalàDeutsch한국어Українська中文\n",
            "\n",
            "Edit links\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ArticleTalk\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "English\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ReadEditView history\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tools\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Tools\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\t\tActions\n",
            "\t\n",
            "\n",
            "\n",
            "ReadEditView history\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tGeneral\n",
            "\t\n",
            "\n",
            "\n",
            "What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPrint/export\n",
            "\t\n",
            "\n",
            "\n",
            "Download as PDFPrintable version\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tIn other projects\n",
            "\t\n",
            "\n",
            "\n",
            "Wikimedia CommonsWikidata item\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Appearance\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "From Wikipedia, the free encyclopedia\n",
            "\n",
            "\n",
            "Type of information retrieval using LLMs\n",
            "Retrieval-Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.[1]  \n",
            "Use cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.[2]\n",
            "\n",
            "\n",
            "Process[edit]\n",
            "The RAG process is made up of four key stages.[3] First, all the data must be prepared and indexed for use by the LLM. Thereafter, each query consists of a retrieval,[4] augmentation, and generation phase.[1]\n",
            "\n",
            "Indexing[edit]\n",
            "Typically, the data to be referenced is converted into LLM embeddings, numerical representations in the form of large vectors. RAG can be used on unstructured (usually text), semi-structured, or structured data (for example knowledge graphs).[1] These embeddings are then stored in a vector database to allow for document retrieval.\n",
            "\n",
            "Overview of RAG process, combining external documents and user input into an LLM prompt to get tailored output\n",
            "Retrieval[edit]\n",
            "Given a user query, a document retriever is first called to select the most relevant documents that will be used to augment the query.[5] This comparison can be done using a variety of methods, which depend in part on the type of indexing used.[1]\n",
            "\n",
            "Augmentation[edit]\n",
            "The model feeds this relevant retrieved information into the LLM via prompt engineering of the user's original query.[2] Newer implementations (as of 2023[update]) can also incorporate specific augmentation modules with abilities such as expanding queries into multiple domains and using memory and self-improvement to learn from previous retrievals.[1]\n",
            "\n",
            "Generation[edit]\n",
            "Finally, the LLM can generate output based on both the query and the retrieved documents.[6] Some models incorporate extra steps to improve output, such as the re-ranking of retrieved information, context selection, and fine-tuning.[1]\n",
            "\n",
            "Improvements[edit]\n",
            "Improvements to the basic process above can be applied at different stages in the RAG flow. \n",
            "\n",
            "Encoder[edit]\n",
            "These methods center around the encoding of text as either dense or sparse vectors. Sparse vectors, used to encode the identity of a word, are typically dictionary length and contain almost all zeros. Dense vectors, used to encode meaning, are much smaller and contain far fewer zeros. Several enhancements can be made to the way similarities are calculated in the vector stores (databases).  \n",
            "\n",
            "Performance can be improved with faster dot products, approximate nearest neighbors, or centroid searches.[7]\n",
            "Accuracy can be improved with Late Interactions.[clarification needed][8]\n",
            "Hybrid vectors: dense vector representations can be combined with sparse one-hot vectors in order to use the faster sparse dot products rather than the slower dense ones.[9]  Other[clarification needed] methods can combine sparse methods (BM25, SPLADE) with dense ones like DRAGON.\n",
            "Retriever-centric methods[edit]\n",
            "These methods focus on improving the quality of hits from the vector database:\n",
            "\n",
            "pre-train the retriever using the Inverse Cloze Task.[10]\n",
            "progressive data augmentation.  The method of Dragon samples difficult negatives to train a dense vector  retriever.[11]\n",
            "Under supervision, train the retriever for a given generator.  Given a prompt and the desired answer, retrieve the top-k vectors, and feed those vectors into the generator to achieve a perplexity score for the correct answer.  Then minimize the KL-divergence between the observed retrieved vectors probability and LM likelihoods to adjust the retriever.[12]\n",
            "use reranking to train the retriever.[13]\n",
            "\n",
            "\n",
            "Language model[edit]\n",
            "\n",
            "Retro language model for RAG.  Each Retro block consists of Attention, Chunked Cross Attention, and Feed Forward layers.  Black-lettered boxes show data being changed, and blue lettering shows the algorithm performing the changes.\n",
            "By redesigning the language model with the retriever in mind, a 25-time smaller network can get comparable perplexity as its much larger counterparts.[14]  Because it is trained from scratch, this method (Retro) incurs the high cost of training runs that the original RAG scheme avoided.  The hypothesis is that by giving domain knowledge during training, Retro needs less focus on the domain and can devote its smaller weight resources only to language semantics.  The redesigned language model is shown here.  \n",
            "It has been reported that Retro is not reproducible, so modifications were made to make it so.  The more reproducible version is called Retro++ and includes in-context RAG.[15]\n",
            "\n",
            "Chunking[edit]\n",
            "This section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: \"Retrieval-augmented generation\" – news · newspapers · books · scholar · JSTOR (October 2024) (Learn how and when to remove this message)\n",
            "Chunking involves various strategies for breaking up the data into vectors so the retriever can find details in it.\n",
            "\n",
            "\n",
            "Different data styles have patterns that correct chunking can take advantage of.\n",
            "Three types of chunking strategies are:\n",
            "\n",
            "Fixed length with overlap. This is fast and easy.  Overlapping consecutive chunks helps to maintain semantic context across chunks.\n",
            "Syntax-based chunks can break the document up into sentences.  Libraries such as spaCy or NLTK can also help.\n",
            "File format-based chunking. Certain file types have natural chunks built in, and it's best to respect them.  For example, code files are best chunked and vectorized as whole functions or classes.  HTML files should leave <table> or base64 encoded <img> elements intact.  Similar considerations should be taken for pdf files.  Libraries such as Unstructured or Langchain can assist with this method.\n",
            "Knowledge Graphs[edit]\n",
            "Rather than using documents as a source to vectorize and retrieve from, Knowledge Graphs can be used.  One can start with a set of documents, books, or other bodies of text, and convert them to a knowledge graph using one of many methods, including language models.  Once the knowledge graph is created, subgraphs can be vectorized, stored in a vector database, and used for retrieval as in plain RAG.  The advantage here is that graphs has more recognizable structure than strings of text and this structure can help retrieve more relevant facts for generation.  Sometimes this approach is called GraphRAG.\n",
            "\n",
            "Hybrid Search[edit]\n",
            "Sometimes vector database searches can miss key facts needed to answer a user's question.  One way to mitigate this is to do a traditional text search, add those results to the text chunks linked to the retrieved vectors from the vector search, and feed the combined hybrid text into the language model for generation.\n",
            "\n",
            "Challenges[edit]\n",
            "If the external data source is large, retrieval can be slow. The use of RAG does not completely eliminate the general challenges faced by LLMs, including hallucination.[5][16]\n",
            "\n",
            "References[edit]\n",
            "\n",
            "\n",
            "^ a b c d e f Gao, Yunfan; Xiong, Yun; Gao, Xinyu; Jia, Kangxiang; Pan, Jinliu; Bi, Yuxi; Dai, Yi; Sun, Jiawei; Wang, Meng; Wang, Haofen (2023). \"Retrieval-Augmented Generation for Large Language Models: A Survey\". arXiv:2312.10997 [cs.CL].\n",
            "\n",
            "^ a b \"What is RAG? - Retrieval-Augmented Generation AI Explained - AWS\". Amazon Web Services, Inc. Retrieved 16 July 2024.\n",
            "\n",
            "^ \"What is Retrieval Augmented Generation?\". Roboflow Blog. 2023-11-16. Retrieved 2025-02-05.\n",
            "\n",
            "^ \"Evolving Interactions | Looking Glass 2024\". Thoughtworks. Retrieved 2024-12-12.\n",
            "\n",
            "^ a b \"Next-Gen Large Language Models: The Retrieval-Augmented Generation (RAG) Handbook\". freeCodeCamp.org. 11 June 2024. Retrieved 16 July 2024.\n",
            "\n",
            "^ Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal, Naman; Küttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rocktäschel, Tim; Riedel, Sebastian; Kiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\". Advances in Neural Information Processing Systems. 33. Curran Associates, Inc.: 9459–9474. arXiv:2005.11401.\n",
            "\n",
            "^  \"faiss\". GitHub. \n",
            "\n",
            "^ Khattab, Omar; Zaharia, Matei (2020). \"\"ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT\"\". doi:10.1145/3397271.3401075. \n",
            "\n",
            "^ Formal, Thibault; Lassance, Carlos; Piwowarski, Benjamin; Clinchant, Stéphane (2021). \"\"SPLADE v2: Sparse Lexical and Expansion Model for Information Retrieval\"\". arXiv:2109.10086 [cs.IR]. \n",
            "\n",
            "^  Lee, Kenton; Chang, Ming-Wei; Toutanova, Kristina (2019). \"\"Latent Retrieval for Weakly Supervised Open Domain Question Answering\"\" (PDF). \n",
            "\n",
            "^ Lin, Sheng-Chieh; Asai, Akari (2023). \"\"How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval\"\" (PDF). \n",
            "\n",
            "^ Shi, Weijia; Min, Sewon (2024). \"REPLUG: Retrieval-Augmented Black-Box Language Models\". \"REPLUG: Retrieval-Augmented Black-Box Language Models\". pp. 8371–8384. arXiv:2301.12652. doi:10.18653/v1/2024.naacl-long.463. \n",
            "\n",
            "^ Ram, Ori; Levine, Yoav; Dalmedigos, Itay; Muhlgay, Dor; Shashua, Amnon; Leyton-Brown, Kevin; Shoham, Yoav (2023). \"\"In-Context Retrieval-Augmented Language Models\"\". Transactions of the Association for Computational Linguistics. 11: 1316–1331. arXiv:2302.00083. doi:10.1162/tacl_a_00605. \n",
            "\n",
            "^ Borgeaud, Sebastian; Mensch, Arthur (2021). \"\"Improving language models by retrieving from trillions of tokens\"\" (PDF). \n",
            "\n",
            "^ Wang, Boxin; Ping, Wei (2023). \"\"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study\"\" (PDF). \n",
            "\n",
            "^ Magesh, Varun; Surani, Faiz; Dahl, Matthew; Suzgun, Mirac; Manning, Christopher D.; Ho, Daniel E. (2024-05-30). \"Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools\". arXiv:2405.20362 [cs.CL].\n",
            "\n",
            "\n",
            "vteGenerative AIConcepts\n",
            "Autoencoder\n",
            "Deep learning\n",
            "Generative adversarial network\n",
            "Generative pre-trained transformer\n",
            "Large language model\n",
            "Neural network\n",
            "Prompt engineering\n",
            "Retrieval-augmented generation\n",
            "Reinforcement learning from human feedback\n",
            "Self-supervised learning\n",
            "Transformer\n",
            "Variational autoencoder\n",
            "Vision transformer\n",
            "Word embedding\n",
            "ModelsText\n",
            "Claude\n",
            "DBRX\n",
            "Gemini\n",
            "GPT\n",
            "1\n",
            "2\n",
            "3\n",
            "J\n",
            "ChatGPT\n",
            "4\n",
            "4o\n",
            "o1\n",
            "o3\n",
            "Grok\n",
            "Granite\n",
            "Llama\n",
            "Mistral Large\n",
            "PanGu-Σ\n",
            "Qwen\n",
            "Image\n",
            "Aurora\n",
            "DALL-E\n",
            "Firefly\n",
            "Flux\n",
            "Ideogram\n",
            "Midjourney\n",
            "Stable Diffusion\n",
            "Video\n",
            "Dream Machine\n",
            "Gen-3 Alpha\n",
            "Hailuo AI\n",
            "Kling\n",
            "Sora\n",
            "Veo\n",
            "VideoPoet\n",
            "Music\n",
            "Udio\n",
            "Suno AI\n",
            "Companies\n",
            "01.AI\n",
            "Alibaba\n",
            "Anthropic\n",
            "Baichuan\n",
            "DeepSeek\n",
            "ElevenLabs\n",
            "Google DeepMind\n",
            "Hugging Face\n",
            "Kuaishou\n",
            "Meta AI\n",
            "MiniMax\n",
            "Mistral AI\n",
            "Moonshot AI\n",
            "OpenAI\n",
            "Runway\n",
            "Stability AI\n",
            "Synthesia\n",
            "xAI\n",
            "Zhipu AI\n",
            "\n",
            " Category\n",
            " Commons\n",
            "\n",
            "vteArtificial intelligence (AI)History (timeline)Concepts\n",
            "Parameter\n",
            "Hyperparameter\n",
            "Loss functions\n",
            "Regression\n",
            "Bias–variance tradeoff\n",
            "Double descent\n",
            "Overfitting\n",
            "Clustering\n",
            "Gradient descent\n",
            "SGD\n",
            "Quasi-Newton method\n",
            "Conjugate gradient method\n",
            "Backpropagation\n",
            "Attention\n",
            "Convolution\n",
            "Normalization\n",
            "Batchnorm\n",
            "Activation\n",
            "Softmax\n",
            "Sigmoid\n",
            "Rectifier\n",
            "Gating\n",
            "Weight initialization\n",
            "Regularization\n",
            "Datasets\n",
            "Augmentation\n",
            "Prompt engineering\n",
            "Reinforcement learning\n",
            "Q-learning\n",
            "SARSA\n",
            "Imitation\n",
            "Policy gradient\n",
            "Diffusion\n",
            "Latent diffusion model\n",
            "Autoregression\n",
            "Adversary\n",
            "RAG\n",
            "Uncanny valley\n",
            "RLHF\n",
            "Self-supervised learning\n",
            "Recursive self-improvement\n",
            "Word embedding\n",
            "Hallucination\n",
            "Applications\n",
            "Machine learning\n",
            "In-context learning\n",
            "Artificial neural network\n",
            "Deep learning\n",
            "Language model\n",
            "Large language model\n",
            "NMT\n",
            "Artificial general intelligence\n",
            "ImplementationsAudio–visual\n",
            "AlexNet\n",
            "WaveNet\n",
            "Human image synthesis\n",
            "HWR\n",
            "OCR\n",
            "Speech synthesis\n",
            "15.ai\n",
            "ElevenLabs\n",
            "Speech recognition\n",
            "Whisper\n",
            "Facial recognition\n",
            "AlphaFold\n",
            "Text-to-image models\n",
            "Aurora\n",
            "DALL-E\n",
            "Firefly\n",
            "Flux\n",
            "Ideogram\n",
            "Imagen\n",
            "Midjourney\n",
            "Stable Diffusion\n",
            "Text-to-video models\n",
            "Dream Machine\n",
            "Gen-3 Alpha\n",
            "Hailuo AI\n",
            "Kling\n",
            "Sora\n",
            "Veo\n",
            "Music generation\n",
            "Suno AI\n",
            "Udio\n",
            "Text\n",
            "Word2vec\n",
            "Seq2seq\n",
            "GloVe\n",
            "BERT\n",
            "T5\n",
            "Llama\n",
            "Chinchilla AI\n",
            "PaLM\n",
            "GPT\n",
            "1\n",
            "2\n",
            "3\n",
            "J\n",
            "ChatGPT\n",
            "4\n",
            "4o\n",
            "o1\n",
            "o3\n",
            "Claude\n",
            "Gemini\n",
            "chatbot\n",
            "Grok\n",
            "LaMDA\n",
            "BLOOM\n",
            "Project Debater\n",
            "IBM Watson\n",
            "IBM Watsonx\n",
            "Granite\n",
            "PanGu-Σ\n",
            "DeepSeek\n",
            "Qwen\n",
            "Decisional\n",
            "AlphaGo\n",
            "AlphaZero\n",
            "OpenAI Five\n",
            "Self-driving car\n",
            "MuZero\n",
            "Action selection\n",
            "AutoGPT\n",
            "Robot control\n",
            "People\n",
            "Alan Turing\n",
            "Warren Sturgis McCulloch\n",
            "Walter Pitts\n",
            "John von Neumann\n",
            "Claude Shannon\n",
            "Marvin Minsky\n",
            "John McCarthy\n",
            "Nathaniel Rochester\n",
            "Allen Newell\n",
            "Cliff Shaw\n",
            "Herbert A. Simon\n",
            "Oliver Selfridge\n",
            "Frank Rosenblatt\n",
            "Bernard Widrow\n",
            "Joseph Weizenbaum\n",
            "Seymour Papert\n",
            "Seppo Linnainmaa\n",
            "Paul Werbos\n",
            "Jürgen Schmidhuber\n",
            "Yann LeCun\n",
            "Geoffrey Hinton\n",
            "John Hopfield\n",
            "Yoshua Bengio\n",
            "Lotfi A. Zadeh\n",
            "Stephen Grossberg\n",
            "Alex Graves\n",
            "Andrew Ng\n",
            "Fei-Fei Li\n",
            "Alex Krizhevsky\n",
            "Ilya Sutskever\n",
            "Demis Hassabis\n",
            "David Silver\n",
            "Ian Goodfellow\n",
            "Andrej Karpathy\n",
            "Architectures\n",
            "Neural Turing machine\n",
            "Differentiable neural computer\n",
            "Transformer\n",
            "Vision transformer (ViT)\n",
            "Recurrent neural network (RNN)\n",
            "Long short-term memory (LSTM)\n",
            "Gated recurrent unit (GRU)\n",
            "Echo state network\n",
            "Multilayer perceptron (MLP)\n",
            "Convolutional neural network (CNN)\n",
            "Residual neural network (RNN)\n",
            "Highway network\n",
            "Mamba\n",
            "Autoencoder\n",
            "Variational autoencoder (VAE)\n",
            "Generative adversarial network (GAN)\n",
            "Graph neural network (GNN)\n",
            "\n",
            " Portals\n",
            "Technology\n",
            " Category\n",
            "Artificial neural networks\n",
            "Machine learning\n",
            " List\n",
            "Companies\n",
            "Projects\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Retrieved from \"https://en.wikipedia.org/w/index.php?title=Retrieval-augmented_generation&oldid=1274165718\"\n",
            "Categories: Large language modelsNatural language processingInformation retrieval systemsGenerative artificial intelligenceHidden categories: Articles with short descriptionShort description is different from WikidataArticles containing potentially dated statements from 2023All articles containing potentially dated statementsWikipedia articles needing clarification from August 2024Articles needing additional references from October 2024All articles needing additional references\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " This page was last edited on 5 February 2025, at 20:08 (UTC).\n",
            "Text is available under the Creative Commons Attribution-ShareAlike 4.0 License;\n",
            "additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n",
            "\n",
            "\n",
            "Privacy policy\n",
            "About Wikipedia\n",
            "Disclaimers\n",
            "Contact Wikipedia\n",
            "Code of Conduct\n",
            "Developers\n",
            "Statistics\n",
            "Cookie statement\n",
            "Mobile view\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle the table of contents\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Retrieval-augmented generation\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5 languages\n",
            "\n",
            "\n",
            "Add topic\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(docs)\n",
        "for doc in docs:\n",
        "    print(doc.metadata)\n",
        "    print(doc.page_content)\n",
        "\n",
        "new_docs = []\n",
        "for doc in docs:\n",
        "    new_doc = doc\n",
        "    new_doc.page_content = doc.page_content[:1000]\n",
        "    new_docs.append(new_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "431c9506-c6c0-463b-af77-9291a63f1d26",
      "metadata": {
        "id": "431c9506-c6c0-463b-af77-9291a63f1d26"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "chain = (\n",
        "    {\"doc\": lambda x: x.page_content}\n",
        "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
        "    | ChatGroq()\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "summaries = chain.batch(new_docs, {\"max_concurrency\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9fb1ce86",
      "metadata": {
        "id": "9fb1ce86",
        "outputId": "f41dff03-42a4-41d2-bb0f-8a28e440fb81"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Retrieval-Augmented Generation (RAG) is an AI framework that combines traditional information retrieval systems with generative large language models. RAG enhances the accuracy, timeliness, and relevance of AI-generated content by integrating data and world knowledge with language skills. The RAG process involves retrieving and pre-processing relevant information from external data sources, such as web pages, knowledge bases, and databases. This information is then utilized to generate more grounded and specific outputs for users. To learn more and get started for free, you can access the e-book \"Unlock your \\'Enterprise Truth\\'\" and explore Google Cloud\\'s Vertex AI Search and DIY RAG options.',\n",
              " 'Retrieval-augmented generation is a method of generating responses to queries that involves first retrieving relevant documents from a large corpus of text, and then using those documents to inform the response generation. The process involves four main steps: indexing, retrieval, augmentation, and generation. Indexing involves pre-processing and encoding the text corpus to enable efficient retrieval. Retrieval involves searching the indexed corpus to find relevant documents. Augmentation involves incorporating the retrieved documents into the response generation process. Generation involves using a language model to produce a final response based on the input query and the retrieved documents. There are several improvements to retrieval-augmented generation that have been proposed, including using more sophisticated encoders, retriever-centric methods, language models, chunking, knowledge graphs, and hybrid search.']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "dc5614c1-121c-4ad5-8609-cc0e4a633ee9",
      "metadata": {
        "id": "dc5614c1-121c-4ad5-8609-cc0e4a633ee9"
      },
      "outputs": [],
      "source": [
        "from langchain.storage import InMemoryByteStore\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "hf_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(collection_name=\"summaries\",\n",
        "                     embedding_function=hf_embeddings)\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryByteStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "# The retriever\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    byte_store=store,\n",
        "    id_key=id_key,\n",
        ")\n",
        "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
        "\n",
        "# Docs linked to summaries\n",
        "summary_docs = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(summaries)\n",
        "]\n",
        "\n",
        "# Add\n",
        "retriever.vectorstore.add_documents(summary_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "90936856",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading flatbuffers-25.1.24-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: protobuf in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.26.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached websockets-14.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: filelock in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.9.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Using cached fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "Downloading grpcio-1.70.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)\n",
            "Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.11.0-py2.py3-none-any.whl (72 kB)\n",
            "Using cached typer-0.15.1-py3-none-any.whl (44 kB)\n",
            "Using cached uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Using cached websockets-14.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading flatbuffers-25.1.24-py2.py3-none-any.whl (30 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Using cached cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=53b9b3957727f3e43f837bbbf55535eb400bfef8541f700de79ebd748758a622\n",
            "  Stored in directory: /home/trung/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, flatbuffers, durationpy, wrapt, websockets, websocket-client, uvloop, uvicorn, tomli, shellingham, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, importlib-resources, humanfriendly, httptools, grpcio, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, googleapis-common-protos, deprecated, coloredlogs, build, typer, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, fastapi, opentelemetry-semantic-conventions, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth-zoo 2024.12.1 requires protobuf<4.0.0, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 cachetools-5.5.1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.8 flatbuffers-25.1.24 google-auth-2.38.0 googleapis-common-protos-1.66.0 grpcio-1.70.0 httptools-0.6.4 humanfriendly-10.0 importlib-resources-6.5.2 kubernetes-32.0.0 mmh3-5.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 posthog-3.11.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 requests-oauthlib-2.0.0 rsa-4.9 shellingham-1.5.4 starlette-0.45.3 tomli-2.2.1 typer-0.15.1 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 websocket-client-1.8.0 websockets-14.2 wrapt-1.17.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "84b531f8",
      "metadata": {
        "id": "84b531f8",
        "outputId": "44fa141f-332b-41b4-aa74-af5c032bc204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['6d570b08-c111-47b5-a195-5d4f60265c72',\n",
              " '8c09b199-5afc-47d9-821c-616687d94d60']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8a849c72",
      "metadata": {
        "id": "8a849c72",
        "outputId": "d2e490e9-68a6-4dc3-c321-5380fe62abdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://cloud.google.com/use-cases/retrieval-augmented-generation', 'title': 'What is Retrieval-Augmented Generation (RAG)? | Google Cloud', 'description': 'Retrieval-augmented generation (RAG) combines LLMs with external knowledge bases to improve their outputs. Learn more with Google Cloud.', 'language': 'en-US'}, page_content='What is Retrieval-Augmented Generation (RAG)? | Google CloudPage ContentsTopicsRAGWhat is Retrieval-Augmented Generation (RAG)?RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as search and databases) with the capabilities of generative large language models (LLMs). By combining your data and world knowledge with LLM language skills, grounded generation is more accurate, up-to-date, and relevant to your specific needs. Check out this e-book to unlock your “Enterprise Truth.”Get started for free35:30Grounding for Gemini with Vertex AI Search and DIY RAGHow does Retrieval-Augmented Generation work?RAGs operate with a few main steps to help enhance generative AI outputs:\\xa0Retrieval and pre-processing: RAGs leverage powerful search algorithms to query external data, such as web pages, knowledge bases, and databases. Once retrieved, the relevant information undergoes pre-processing, including tokenization, '),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'title': 'Retrieval-augmented generation - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nRetrieval-augmented generation - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nProcess\\n\\n\\n\\n\\nToggle Process subsection\\n\\n\\n\\n\\n\\n1.1\\nIndexing\\n\\n\\n\\n\\n\\n\\n\\n\\n1.2\\nRetrieval\\n\\n\\n\\n\\n\\n\\n\\n\\n1.3\\nAugmentation\\n\\n\\n\\n\\n\\n\\n\\n\\n1.4\\nGeneration\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nImprovements\\n\\n\\n\\n\\nToggle Improvements subsection\\n\\n\\n\\n\\n\\n2.1\\nEncoder\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nRetriever-centric methods\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nLanguage model\\n\\n\\n\\n\\n\\n\\n\\n\\n2.4\\nChunking\\n\\n\\n\\n\\n\\n\\n\\n\\n2.5\\nKnowledge Graphs\\n\\n\\n\\n\\n\\n\\n\\n\\n2.6\\nHybrid Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nChall')]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.docstore.mget(doc_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f111ca83-3e56-4785-bac3-99948cd8df1b",
      "metadata": {
        "id": "f111ca83-3e56-4785-bac3-99948cd8df1b",
        "outputId": "6be2a2a7-6285-424b-93f9-9694879ec2ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'doc_id': '6d570b08-c111-47b5-a195-5d4f60265c72'}, page_content='Retrieval-Augmented Generation (RAG) is an AI framework that combines traditional information retrieval systems with generative large language models. RAG enhances the accuracy, timeliness, and relevance of AI-generated content by integrating data and world knowledge with language skills. The RAG process involves retrieving and pre-processing relevant information from external data sources, such as web pages, knowledge bases, and databases. This information is then utilized to generate more grounded and specific outputs for users. To learn more and get started for free, you can access the e-book \"Unlock your \\'Enterprise Truth\\'\" and explore Google Cloud\\'s Vertex AI Search and DIY RAG options.')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What is agent\"\n",
        "sub_docs = vectorstore.similarity_search(query,k=1)\n",
        "sub_docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "729074f9-8bde-4c76-a7da-4cc0e50ed52d",
      "metadata": {
        "id": "729074f9-8bde-4c76-a7da-4cc0e50ed52d",
        "outputId": "550c951d-de4b-4977-9480-7f6476b9015a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1601037/3791815623.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retrieved_docs = retriever.get_relevant_documents(query,n_results=1)\n",
            "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'What is Retrieval-Augmented Generation (RAG)? | Google CloudPage ContentsTopicsRAGWhat is Retrieval-Augmented Generation (RAG)?RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as search and databases) with the capabilities of generative large language models (LLMs). By combining your data and world knowledge with LLM language skills, grounded generation is more accurate, up-to-date, and relevant to your specifi'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs = retriever.get_relevant_documents(query,n_results=1)\n",
        "retrieved_docs[0].page_content[0:500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09151ce-aea1-4574-84ab-a72f17bf59b4",
      "metadata": {
        "id": "d09151ce-aea1-4574-84ab-a72f17bf59b4"
      },
      "source": [
        "## Part 13: ColBERT\n",
        "\n",
        "RAGatouille makes it as simple to use ColBERT.\n",
        "\n",
        "ColBERT generates a contextually influenced vector for each token in the passages.\n",
        "\n",
        "ColBERT similarly generates vectors for each token in the query.\n",
        "\n",
        "Then, the score of each document is the sum of the maximum similarity of each query embedding to any of the document embeddings:\n",
        "\n",
        "See [here](https://hackernoon.com/how-colbert-helps-developers-overcome-the-limits-of-rag) and [here](https://python.langchain.com/docs/integrations/retrievers/ragatouille) and [here](https://til.simonwillison.net/llms/colbert-ragatouille)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd11cd55",
      "metadata": {},
      "source": [
        "- sử dụng colbert là hệ RAG pretrained model luôn\n",
        "- sử dụng index() để indexing tạo bộ database\n",
        "- sử dụng search() để retrieval\n",
        "- sử dụng invoke() để thực hiện trả về output từ input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "TxcmPHugWRY5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxcmPHugWRY5",
        "outputId": "e338f6d0-178a-412c-f5f7-ae2397d65179"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ragatouille\n",
            "  Downloading ragatouille-0.0.8.post4-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting colbert-ai==0.2.19 (from ragatouille)\n",
            "  Downloading colbert-ai-0.2.19.tar.gz (86 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting faiss-cpu<2.0.0,>=1.7.4 (from ragatouille)\n",
            "  Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting fast-pytorch-kmeans==0.2.0.1 (from ragatouille)\n",
            "  Downloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: langchain>=0.1.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from ragatouille) (0.3.17)\n",
            "Requirement already satisfied: langchain_core>=0.1.4 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from ragatouille) (0.3.33)\n",
            "Collecting llama-index>=0.7 (from ragatouille)\n",
            "  Downloading llama_index-0.12.16-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting onnx<2.0.0,>=1.15.0 (from ragatouille)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting sentence-transformers<3.0.0,>=2.2.2 (from ragatouille)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting srsly==2.4.8 (from ragatouille)\n",
            "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=1.13 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from ragatouille) (2.5.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from ragatouille) (4.46.3)\n",
            "Collecting voyager<3.0.0,>=2.0.2 (from ragatouille)\n",
            "  Downloading voyager-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
            "Collecting bitarray (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: datasets in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (3.1.0)\n",
            "Collecting flask (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting git-python (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
            "Requirement already satisfied: python-dotenv in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.0.1)\n",
            "Collecting ninja (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: scipy in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from colbert-ai==0.2.19->ragatouille) (4.67.1)\n",
            "Collecting ujson (from colbert-ai==0.2.19->ragatouille)\n",
            "  Using cached ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: numpy in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from fast-pytorch-kmeans==0.2.0.1->ragatouille) (1.26.4)\n",
            "Collecting pynvml (from fast-pytorch-kmeans==0.2.0.1->ragatouille)\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.3 (from srsly==2.4.8->ragatouille)\n",
            "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from faiss-cpu<2.0.0,>=1.7.4->ragatouille) (24.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (2.10.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain>=0.1.0->ragatouille) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain_core>=0.1.4->ragatouille) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langchain_core>=0.1.4->ragatouille) (4.12.2)\n",
            "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl.metadata (727 bytes)\n",
            "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.16 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_core-0.12.16.post1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index>=0.7->ragatouille)\n",
            "  Using cached llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_llms_openai-0.3.17-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_readers_file-0.4.4-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index>=0.7->ragatouille)\n",
            "  Using cached llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index>=0.7->ragatouille) (3.9.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (5.29.3)\n",
            "Requirement already satisfied: scikit-learn in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.26.5)\n",
            "Requirement already satisfied: Pillow in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (11.0.0)\n",
            "Requirement already satisfied: filelock in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (3.16.1)\n",
            "Requirement already satisfied: networkx in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from torch>=1.13->ragatouille) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13->ragatouille) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->ragatouille) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->ragatouille) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->ragatouille) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->ragatouille) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->ragatouille) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->ragatouille) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.1.0->ragatouille) (1.18.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core>=0.1.4->ragatouille) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (0.23.0)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille)\n",
            "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: dataclasses-json in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (1.2.18)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille)\n",
            "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille)\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (1.6.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (0.8.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_cloud-0.1.11-py3-none-any.whl.metadata (912 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (4.13.3)\n",
            "Requirement already satisfied: pandas in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (2.2.3)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille)\n",
            "  Downloading pypdf-5.2.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille)\n",
            "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from nltk>3.8.1->llama-index>=0.7->ragatouille) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from nltk>3.8.1->llama-index>=0.7->ragatouille) (1.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->ragatouille) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.1.0->ragatouille) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.1.0->ragatouille) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.1.0->ragatouille) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.1.0->ragatouille) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.1.0->ragatouille) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.1.0->ragatouille) (3.1.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n",
            "Collecting Werkzeug>=3.1 (from flask->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting itsdangerous>=2.2 (from flask->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting blinker>=1.9 (from flask->colbert-ai==0.2.19->ragatouille)\n",
            "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from jinja2->torch>=1.13->ragatouille) (3.0.2)\n",
            "Requirement already satisfied: gitpython in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from git-python->colbert-ai==0.2.19->ragatouille) (3.1.43)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml->fast-pytorch-kmeans==0.2.0.1->ragatouille)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.5.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (2.6)\n",
            "Requirement already satisfied: anyio in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (1.9.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille)\n",
            "  Using cached jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: sniffio in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.16->llama-index>=0.7->ragatouille) (3.26.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from gitpython->git-python->colbert-ai==0.2.19->ragatouille) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.1.0->ragatouille) (1.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille) (5.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index>=0.7->ragatouille) (1.17.0)\n",
            "Downloading ragatouille-0.0.8.post4-py3-none-any.whl (41 kB)\n",
            "Downloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl (8.8 kB)\n",
            "Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
            "Downloading faiss_cpu-1.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.12.16-py3-none-any.whl (6.9 kB)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "Downloading voyager-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.12.16.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_llms_openai-0.3.17-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.4-py3-none-any.whl (39 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading bitarray-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "Downloading flask-3.1.0-py3-none-any.whl (102 kB)\n",
            "Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Using cached ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading llama_cloud-0.1.11-py3-none-any.whl (250 kB)\n",
            "Downloading llama_parse-0.5.20-py3-none-any.whl (16 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "Downloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
            "Downloading pypdf-5.2.0-py3-none-any.whl (298 kB)\n",
            "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "Building wheels for collected packages: colbert-ai\n",
            "  Building wheel for colbert-ai (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114759 sha256=98377d8b8c18bb4e46b50901afe332f84187ac6121871e6a50183c9ffe02f509\n",
            "  Stored in directory: /home/trung/.cache/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\n",
            "Successfully built colbert-ai\n",
            "Installing collected packages: striprtf, nvidia-ml-py, filetype, dirtyjson, bitarray, Werkzeug, voyager, ujson, pypdf, pynvml, onnx, ninja, jiter, itsdangerous, faiss-cpu, catalogue, blinker, srsly, flask, openai, llama-cloud, git-python, llama-index-core, fast-pytorch-kmeans, sentence-transformers, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, colbert-ai, llama-index-program-openai, llama-index-question-gen-openai, llama-index, ragatouille\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.3.1\n",
            "    Uninstalling sentence-transformers-3.3.1:\n",
            "      Successfully uninstalled sentence-transformers-3.3.1\n",
            "Successfully installed Werkzeug-3.1.3 bitarray-3.0.0 blinker-1.9.0 catalogue-2.0.10 colbert-ai-0.2.19 dirtyjson-1.0.8 faiss-cpu-1.10.0 fast-pytorch-kmeans-0.2.0.1 filetype-1.2.0 flask-3.1.0 git-python-1.0.3 itsdangerous-2.2.0 jiter-0.8.2 llama-cloud-0.1.11 llama-index-0.12.16 llama-index-agent-openai-0.4.3 llama-index-cli-0.4.0 llama-index-core-0.12.16.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.4 llama-index-llms-openai-0.3.17 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.4 llama-index-readers-llama-parse-0.4.0 llama-parse-0.5.20 ninja-1.11.1.3 nvidia-ml-py-12.570.86 onnx-1.17.0 openai-1.61.1 pynvml-12.0.0 pypdf-5.2.0 ragatouille-0.0.8.post4 sentence-transformers-2.7.0 srsly-2.4.8 striprtf-0.0.26 ujson-5.10.0 voyager-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ragatouille"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "96deaaa9-5101-48a5-a93d-b8af0122430f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "f55f34da36fb4016a4a0494086c64641",
            "0b1d585d85824f888d39522ecb8a6f1f",
            "5c3f767339684ba894d39282b9edbbb7",
            "fad322935e6b4fbc8276abc2b85e1836",
            "4be9692e8be043c489f06a3abf27c64d",
            "4ba71b0eaff04537bc50bbca33aa4630",
            "7ac87a6e34984140a02a704c3e4ccf48",
            "1e9de6e09f82454381a7becdec58e8bf",
            "f347b06929df4fab84b1ab26338f4af6",
            "033667bb55444c3f9f629dd9ede1ec99",
            "d1773c06eeee4678953761276e51dcf1",
            "22cf57b760304a978df66d62eed18444",
            "ce12ae54e3424ac8835ab37b5d2538a4",
            "6c9de4615d71479ba94ee6c71de73ccb",
            "232ef42c0b9242a993254f861575d96f",
            "4606c9d425314c089779736ccd5e2450",
            "a6116981916849eebf946d98ae8691e0",
            "779f2ee7130e4d44b213dab4098672e2",
            "6b363d6326ea427389d849068c012232",
            "91d690a1ba354771bb838a2b0b18b79e",
            "5dd7c87d28b149cb940316e1349fee7e",
            "3978e89d4c3e4d79b2878d24cb9b9c04",
            "8f75d8d2a1ab4abc8b96fadf5f600dfb",
            "59123ebb89ad4cbdb1e720883ecda233",
            "20d54451d0174a8bb63aceef38882400",
            "4aec2d6583fb43e28748dac7ab2baab0",
            "ed62cedbc6024c61b76131f992e31af2",
            "ac6a1048895c4491ad1e68ae54e8f8e9",
            "5498b24697224a8eb9a4ecfde6ac4846",
            "841c4cb47e564e0ebb8095778d66c009",
            "252fa7545c1743f39d91cac5f3bfd98f",
            "f864969ec82b4317ba1e703c1c8d22c1",
            "c33ad59265ab41aba4c0e1cd7ee3070c",
            "6c255f2548db49dcae4895a12932ce00",
            "9844837561f6449485a618a5ddefabdc",
            "8661582dd02949ab9d922551b764c7b9",
            "ac4a22ba42da4369acd7a615f7e0b863",
            "d22750241cf04e32a11e7bc3a68cc2f4",
            "1b26567be0e547bf9653330ee3e9657a",
            "9dd945ef26ff46a481966617b067213b",
            "1c1157f83feb4b6cad7ef629a67f8e47",
            "9e56ab04c7b54dba911e615c64c8e8c8",
            "8bc753efac9445ddad71fca8a8ed3ae5",
            "8371a09564324bf5ade74da741e1afc6",
            "cc321c998b874fb79b1aedcdbf8eb532",
            "ee1cace3748c49999acec51380c87808",
            "ba5f73bc04a04df1bec10ec485127439",
            "faaa3db108f54b2b8cc68d26f814cb87",
            "4f08bd4dab974813aa757ec9c4aa963a",
            "a7e8f141bc434de6826b9d288710ae71",
            "cbcadf9a603b48acb63dae5b8ae018e3",
            "b75a53aa019d4fb3a1dd49fae3b71028",
            "b5e438a896a44bc58a805ccc5ab03dc4",
            "b9463b08a33e4bdeaa2f13f307c94a4e",
            "8d73beaf48cf49d39b0e0282883443a3",
            "1a13075d97244a8dad0d45bf48378d91",
            "088c9c3f25f7404cb36c641a85026683",
            "c793d1c900904cca8ffedf8aff00d9bc",
            "8623a516b70244efb6d672cd81b142a8",
            "37314ac1be75491fbcb9b1545dc3badc",
            "51cad1a6c9134a1c9b818222ac7138e7",
            "61af1a241ae54cf5ab71425047c34d3d",
            "a924f492ca3f4a5fbd48c57aee80c767",
            "119d9d2a3ae64961a46254e7a0a96e82",
            "c8dcb6be89934c408501870533049506",
            "605810870a4040deb1cd10ab0a057d5a",
            "a711db6e16974e498d689038a66344de",
            "da31decacd0a49fd8804be39dfab86f3",
            "3d3699228def403bbee1a5831c0ef5ca",
            "139fc4cf87d6413b852799dd74e9bab4",
            "46b90df0d418488f90c8543486a98e9e",
            "796ec3b798154839bfba5d5f26ba0eb2",
            "2c02a1c5ce2e44efbe2052dcc585b8ab",
            "ccf0334b4758450892167661416980ab",
            "6468201ba1814586a23be3ed3f78f190",
            "c16840916a2f45f1a11511542aff5b90",
            "b5f3df4f63c84fcf9222e95d5380a899"
          ]
        },
        "id": "96deaaa9-5101-48a5-a93d-b8af0122430f",
        "outputId": "bf1e8d2c-64cf-4918-d452-1f92fff705f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "10b9bfc1-5f2b-4b9e-9934-9844e3b60646",
      "metadata": {
        "id": "10b9bfc1-5f2b-4b9e-9934-9844e3b60646"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def get_wikipedia_page(title: str):\n",
        "    \"\"\"\n",
        "    Retrieve the full text content of a Wikipedia page.\n",
        "\n",
        "    :param title: str - Title of the Wikipedia page.\n",
        "    :return: str - Full text content of the page as raw string.\n",
        "    \"\"\"\n",
        "    # Wikipedia API endpoint\n",
        "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "    # Parameters for the API request\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"titles\": title,\n",
        "        \"prop\": \"extracts\",\n",
        "        \"explaintext\": True,\n",
        "    }\n",
        "\n",
        "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
        "    headers = {\"User-Agent\": \"RAGatouille_tutorial/0.0.1 (ben@clavie.eu)\"}\n",
        "\n",
        "    response = requests.get(URL, params=params, headers=headers)\n",
        "    data = response.json()\n",
        "\n",
        "    # Extracting page content\n",
        "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
        "    return page[\"extract\"] if \"extract\" in page else None\n",
        "\n",
        "full_document = get_wikipedia_page(\"Document_retrieval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2317cc1-7406-4115-84c2-d0527a4ad22e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "a2317cc1-7406-4115-84c2-d0527a4ad22e",
        "outputId": "643d8793-e8f6-40f7-e380-0bfa4e5fa621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----\n",
            "This is a behaviour change from RAGatouille 0.8.0 onwards.\n",
            "This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.\n",
            "If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.\n",
            "--------------------\n",
            "\n",
            "\n",
            "[Feb 06, 10:16:00] #> Creating directory .ragatouille/colbert/indexes/Doc-1 \n",
            "\n",
            "\n",
            "#> Starting...\n",
            "#> Starting...\n",
            "nranks = 2 \t num_gpus = 2 \t device=0\n",
            "nranks = 2 \t num_gpus = 2 \t device=1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n",
            "/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  return torch.cuda.amp.autocast() if self.activated else NullContextManager()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Feb 06, 10:16:06] [1] \t\t #> Encoding 3 passages..\n",
            "[Feb 06, 10:16:06] [0] \t\t #> Encoding 4 passages..\n",
            "[Feb 06, 10:16:08] [0] \t\t avg_doclen_est = 114.16667175292969 \t len(local_sample) = 4\n",
            "[Feb 06, 10:16:08] [1] \t\t avg_doclen_est = 114.16667175292969 \t len(local_sample) = 3\n",
            "[Feb 06, 10:16:08] [0] \t\t Creating 256 partitions.\n",
            "[Feb 06, 10:16:08] [0] \t\t *Estimated* 799 embeddings.\n",
            "[Feb 06, 10:16:08] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/Doc-1/plan.json ..\n",
            "Clustering 775 points in 128D to 256 clusters, redo 1 times, 20 iterations\n",
            "  Preprocessing in 0.00 s\n",
            "  Iteration 19 (0.03 s, search 0.02 s): objective=108.294 imbalance=1.456 nsplit=0       \n",
            "[Feb 06, 10:16:08] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py:256: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sub_sample = torch.load(sub_sample_path)\n",
            "WARNING clustering 775 points to 256 centroids: please provide at least 9984 training points\n",
            "Process Process-2:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 134, in setup_new_process\n",
            "    return_val = callee(config, *args)\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 33, in encode\n",
            "    encoder.run(shared_lists)\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 68, in run\n",
            "    self.train(shared_lists) # Trains centroids from selected passages\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 237, in train\n",
            "    bucket_cutoffs, bucket_weights, avg_residual = self._compute_avg_residual(centroids, heldout)\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 315, in _compute_avg_residual\n",
            "    compressor = ResidualCodec(config=self.config, centroids=centroids, avg_residual=None)\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/indexing/codecs/residual.py\", line 24, in __init__\n",
            "    ResidualCodec.try_load_torch_extensions(self.use_gpu)\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/colbert/indexing/codecs/residual.py\", line 103, in try_load_torch_extensions\n",
            "    decompress_residuals_cpp = load(\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1314, in load\n",
            "    return _jit_compile(\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1721, in _jit_compile\n",
            "    _write_ninja_file_and_build_library(\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1810, in _write_ninja_file_and_build_library\n",
            "    extra_ldflags = _prepare_ldflags(\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1899, in _prepare_ldflags\n",
            "    if (not os.path.exists(_join_cuda_home(extra_lib_dir)) and\n",
            "  File \"/home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n",
            "    raise OSError('CUDA_HOME environment variable is not set. '\n",
            "OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
            "[rank1]:[E206 10:26:08.253878554 ProcessGroupNCCL.cpp:616] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600070 milliseconds before timing out.\n",
            "[rank1]:[E206 10:26:08.264262908 ProcessGroupNCCL.cpp:1785] [PG ID 0 PG GUID 0(default_pg) Rank 1] Exception (either an error or timeout) detected by watchdog at work: 5, last enqueued NCCL work: 5, last completed NCCL work: 4.\n",
            "[rank1]:[E206 10:26:08.264344422 ProcessGroupNCCL.cpp:1834] [PG ID 0 PG GUID 0(default_pg) Rank 1] Timeout at NCCL work: 5, last enqueued NCCL work: 5, last completed NCCL work: 4.\n",
            "[rank1]:[E206 10:26:08.264360462 ProcessGroupNCCL.cpp:630] [Rank 1] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
            "[rank1]:[E206 10:26:08.264372161 ProcessGroupNCCL.cpp:636] [Rank 1] To avoid data inconsistency, we are taking the entire process down.\n",
            "[rank1]:[E206 10:26:08.266919062 ProcessGroupNCCL.cpp:1595] [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600070 milliseconds before timing out.\n",
            "Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f4ba4a71446 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libc10.so)\n",
            "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x7f4ba5d84772 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f4ba5d8bbb3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7f4ba5d8d61d in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #4: <unknown function> + 0x145c0 (0x7f4bee71a5c0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch.so)\n",
            "frame #5: <unknown function> + 0x8609 (0x7f4bf0f95609 in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
            "frame #6: clone + 0x43 (0x7f4bf0d60353 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n",
            "terminate called after throwing an instance of 'c10::DistBackendError'\n",
            "  what():  [PG ID 0 PG GUID 0(default_pg) Rank 1] Process group watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=5, OpType=ALLREDUCE, NumelIn=1, NumelOut=1, Timeout(ms)=600000) ran for 600070 milliseconds before timing out.\n",
            "Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:618 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f4ba4a71446 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libc10.so)\n",
            "frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x282 (0x7f4ba5d84772 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x7f4ba5d8bbb3 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x14d (0x7f4ba5d8d61d in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #4: <unknown function> + 0x145c0 (0x7f4bee71a5c0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch.so)\n",
            "frame #5: <unknown function> + 0x8609 (0x7f4bf0f95609 in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
            "frame #6: clone + 0x43 (0x7f4bf0d60353 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n",
            "Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1601 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7f4ba4a71446 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libc10.so)\n",
            "frame #1: <unknown function> + 0xe4271b (0x7f4ba59fa71b in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so)\n",
            "frame #2: <unknown function> + 0x145c0 (0x7f4bee71a5c0 in /home/trung/.conda/envs/python310/lib/python3.10/site-packages/torch/lib/libtorch.so)\n",
            "frame #3: <unknown function> + 0x8609 (0x7f4bf0f95609 in /lib/x86_64-linux-gnu/libpthread.so.0)\n",
            "frame #4: clone + 0x43 (0x7f4bf0d60353 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "RAG.index(\n",
        "    collection=[full_document],\n",
        "    index_name=\"Doc-1\",\n",
        "    max_document_length=180,\n",
        "    split_documents=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f929e4fd-2175-465d-bd88-664f67caa576",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f929e4fd-2175-465d-bd88-664f67caa576",
        "outputId": "db0ea720-6be3-4e26-b931-2a7d6a6fe063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading searcher for index Doc-1 for the first time... This may take a few seconds\n",
            "[Jul 06, 00:08:11] #> Loading codec...\n",
            "[Jul 06, 00:08:11] #> Loading IVF...\n",
            "[Jul 06, 00:08:11] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "[Jul 06, 00:08:48] #> Loading doclens...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3279.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:08:48] #> Loading codes and residuals...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 130.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:08:48] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Jul 06, 00:09:20] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "Searcher loaded!\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: . What is an example for form based indexing?, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2003, 2019, 2742, 2005, 2433, 2241, 5950, 2075, 1029,\n",
            "         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,\n",
            "         103,  103,  103,  103,  103,  103,  103,  103])\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'content': '== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.',\n",
              "  'score': 25.978090286254883,\n",
              "  'rank': 1,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 2},\n",
              " {'content': '== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.',\n",
              "  'score': 19.45407485961914,\n",
              "  'rank': 2,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 4},\n",
              " {'content': '=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.',\n",
              "  'score': 19.071989059448242,\n",
              "  'rank': 3,\n",
              "  'document_id': '83decb83-f58e-4d89-b9c1-51f09daadcfa',\n",
              "  'passage_id': 3}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = RAG.search(query=\"What is an example for form based indexing?\", k=3)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ca1cbbc7-bd6e-488d-9419-740a62eb097a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca1cbbc7-bd6e-488d-9419-740a62eb097a",
        "outputId": "97fb2c8b-e3fb-49c8-ff8b-f0ed8ae43f94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='== Variations ==\\nThere are two main classes of indexing schemata for document retrieval systems: form based (or word based), and content based indexing. The document classification scheme (or indexing algorithm) in use determines the nature of the document retrieval system.\\n\\n\\n=== Form based ===\\nForm based document retrieval addresses the exact syntactic properties of a text, comparable to substring matching in string searches. The text is generally unstructured and not necessarily in a natural language, the system could for example be used to process large sets of chemical representations in molecular biology. A suffix tree algorithm is an example for form based indexing.'),\n",
              " Document(page_content='== Example: PubMed ==\\nThe PubMed form interface features the \"related articles\" search which works through a comparison of words from the documents\\' title, abstract, and MeSH terms using a word-weighted algorithm.\\n\\n\\n== See also ==\\nCompound term processing\\nDocument classification\\nEnterprise search\\nEvaluation measures (information retrieval)\\nFull text search\\nInformation retrieval\\nLatent semantic indexing\\nSearch engine\\n\\n\\n== References ==\\n\\n\\n== Further reading ==\\nFaloutsos, Christos; Christodoulakis, Stavros (1984). \"Signature files: An access method for documents and its analytical performance evaluation\". ACM Transactions on Information Systems. 2 (4): 267–288. doi:10.1145/2275.357411. S2CID 8120705.'),\n",
              " Document(page_content='=== Content based ===\\nThe content based approach exploits semantic connections between documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an inverted index algorithm.\\nA signature file is a technique that creates a quick and dirty filter, for example a Bloom filter, that will keep all the documents that match to the query and hopefully a few ones that do not. The way this is done is by creating for each file a signature, typically a hash coded version. One method is superimposed coding. A post-processing step is done to discard the false alarms. Since in most cases this structure is inferior to inverted files in terms of speed, size and functionality, it is not used widely. However, with proper parameters it can beat the inverted files in certain environments.')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = RAG.as_langchain_retriever(k=3)\n",
        "retriever.invoke(\"What is an example for form based indexing?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zn5ZK6ycXxqX",
      "metadata": {
        "id": "zn5ZK6ycXxqX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "033667bb55444c3f9f629dd9ede1ec99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088c9c3f25f7404cb36c641a85026683": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51cad1a6c9134a1c9b818222ac7138e7",
            "placeholder": "​",
            "style": "IPY_MODEL_61af1a241ae54cf5ab71425047c34d3d",
            "value": "tokenizer.json: 100%"
          }
        },
        "0b1d585d85824f888d39522ecb8a6f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba71b0eaff04537bc50bbca33aa4630",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac87a6e34984140a02a704c3e4ccf48",
            "value": "artifact.metadata: 100%"
          }
        },
        "119d9d2a3ae64961a46254e7a0a96e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "139fc4cf87d6413b852799dd74e9bab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16840916a2f45f1a11511542aff5b90",
            "placeholder": "​",
            "style": "IPY_MODEL_b5f3df4f63c84fcf9222e95d5380a899",
            "value": " 112/112 [00:00&lt;00:00, 2.63kB/s]"
          }
        },
        "1a13075d97244a8dad0d45bf48378d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_088c9c3f25f7404cb36c641a85026683",
              "IPY_MODEL_c793d1c900904cca8ffedf8aff00d9bc",
              "IPY_MODEL_8623a516b70244efb6d672cd81b142a8"
            ],
            "layout": "IPY_MODEL_37314ac1be75491fbcb9b1545dc3badc"
          }
        },
        "1b26567be0e547bf9653330ee3e9657a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1157f83feb4b6cad7ef629a67f8e47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e9de6e09f82454381a7becdec58e8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20d54451d0174a8bb63aceef38882400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_841c4cb47e564e0ebb8095778d66c009",
            "max": 438349816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_252fa7545c1743f39d91cac5f3bfd98f",
            "value": 438349816
          }
        },
        "22cf57b760304a978df66d62eed18444": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce12ae54e3424ac8835ab37b5d2538a4",
              "IPY_MODEL_6c9de4615d71479ba94ee6c71de73ccb",
              "IPY_MODEL_232ef42c0b9242a993254f861575d96f"
            ],
            "layout": "IPY_MODEL_4606c9d425314c089779736ccd5e2450"
          }
        },
        "232ef42c0b9242a993254f861575d96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd7c87d28b149cb940316e1349fee7e",
            "placeholder": "​",
            "style": "IPY_MODEL_3978e89d4c3e4d79b2878d24cb9b9c04",
            "value": " 743/743 [00:00&lt;00:00, 31.2kB/s]"
          }
        },
        "252fa7545c1743f39d91cac5f3bfd98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c02a1c5ce2e44efbe2052dcc585b8ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37314ac1be75491fbcb9b1545dc3badc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3978e89d4c3e4d79b2878d24cb9b9c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d3699228def403bbee1a5831c0ef5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf0334b4758450892167661416980ab",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6468201ba1814586a23be3ed3f78f190",
            "value": 112
          }
        },
        "4606c9d425314c089779736ccd5e2450": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b90df0d418488f90c8543486a98e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aec2d6583fb43e28748dac7ab2baab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f864969ec82b4317ba1e703c1c8d22c1",
            "placeholder": "​",
            "style": "IPY_MODEL_c33ad59265ab41aba4c0e1cd7ee3070c",
            "value": " 438M/438M [00:03&lt;00:00, 142MB/s]"
          }
        },
        "4ba71b0eaff04537bc50bbca33aa4630": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be9692e8be043c489f06a3abf27c64d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f08bd4dab974813aa757ec9c4aa963a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51cad1a6c9134a1c9b818222ac7138e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5498b24697224a8eb9a4ecfde6ac4846": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59123ebb89ad4cbdb1e720883ecda233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac6a1048895c4491ad1e68ae54e8f8e9",
            "placeholder": "​",
            "style": "IPY_MODEL_5498b24697224a8eb9a4ecfde6ac4846",
            "value": "model.safetensors: 100%"
          }
        },
        "5c3f767339684ba894d39282b9edbbb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e9de6e09f82454381a7becdec58e8bf",
            "max": 1633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f347b06929df4fab84b1ab26338f4af6",
            "value": 1633
          }
        },
        "5dd7c87d28b149cb940316e1349fee7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605810870a4040deb1cd10ab0a057d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61af1a241ae54cf5ab71425047c34d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6468201ba1814586a23be3ed3f78f190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b363d6326ea427389d849068c012232": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c255f2548db49dcae4895a12932ce00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9844837561f6449485a618a5ddefabdc",
              "IPY_MODEL_8661582dd02949ab9d922551b764c7b9",
              "IPY_MODEL_ac4a22ba42da4369acd7a615f7e0b863"
            ],
            "layout": "IPY_MODEL_d22750241cf04e32a11e7bc3a68cc2f4"
          }
        },
        "6c9de4615d71479ba94ee6c71de73ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b363d6326ea427389d849068c012232",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d690a1ba354771bb838a2b0b18b79e",
            "value": 743
          }
        },
        "779f2ee7130e4d44b213dab4098672e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "796ec3b798154839bfba5d5f26ba0eb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac87a6e34984140a02a704c3e4ccf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8371a09564324bf5ade74da741e1afc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "841c4cb47e564e0ebb8095778d66c009": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8623a516b70244efb6d672cd81b142a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8dcb6be89934c408501870533049506",
            "placeholder": "​",
            "style": "IPY_MODEL_605810870a4040deb1cd10ab0a057d5a",
            "value": " 466k/466k [00:00&lt;00:00, 5.60MB/s]"
          }
        },
        "8661582dd02949ab9d922551b764c7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1157f83feb4b6cad7ef629a67f8e47",
            "max": 405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e56ab04c7b54dba911e615c64c8e8c8",
            "value": 405
          }
        },
        "8bc753efac9445ddad71fca8a8ed3ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d73beaf48cf49d39b0e0282883443a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f75d8d2a1ab4abc8b96fadf5f600dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59123ebb89ad4cbdb1e720883ecda233",
              "IPY_MODEL_20d54451d0174a8bb63aceef38882400",
              "IPY_MODEL_4aec2d6583fb43e28748dac7ab2baab0"
            ],
            "layout": "IPY_MODEL_ed62cedbc6024c61b76131f992e31af2"
          }
        },
        "91d690a1ba354771bb838a2b0b18b79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9844837561f6449485a618a5ddefabdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b26567be0e547bf9653330ee3e9657a",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd945ef26ff46a481966617b067213b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9dd945ef26ff46a481966617b067213b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e56ab04c7b54dba911e615c64c8e8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6116981916849eebf946d98ae8691e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a711db6e16974e498d689038a66344de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da31decacd0a49fd8804be39dfab86f3",
              "IPY_MODEL_3d3699228def403bbee1a5831c0ef5ca",
              "IPY_MODEL_139fc4cf87d6413b852799dd74e9bab4"
            ],
            "layout": "IPY_MODEL_46b90df0d418488f90c8543486a98e9e"
          }
        },
        "a7e8f141bc434de6826b9d288710ae71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a924f492ca3f4a5fbd48c57aee80c767": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac4a22ba42da4369acd7a615f7e0b863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc753efac9445ddad71fca8a8ed3ae5",
            "placeholder": "​",
            "style": "IPY_MODEL_8371a09564324bf5ade74da741e1afc6",
            "value": " 405/405 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "ac6a1048895c4491ad1e68ae54e8f8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e438a896a44bc58a805ccc5ab03dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5f3df4f63c84fcf9222e95d5380a899": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b75a53aa019d4fb3a1dd49fae3b71028": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9463b08a33e4bdeaa2f13f307c94a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5f73bc04a04df1bec10ec485127439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b75a53aa019d4fb3a1dd49fae3b71028",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e438a896a44bc58a805ccc5ab03dc4",
            "value": 231508
          }
        },
        "c16840916a2f45f1a11511542aff5b90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c33ad59265ab41aba4c0e1cd7ee3070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c793d1c900904cca8ffedf8aff00d9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a924f492ca3f4a5fbd48c57aee80c767",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_119d9d2a3ae64961a46254e7a0a96e82",
            "value": 466081
          }
        },
        "c8dcb6be89934c408501870533049506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbcadf9a603b48acb63dae5b8ae018e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc321c998b874fb79b1aedcdbf8eb532": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1cace3748c49999acec51380c87808",
              "IPY_MODEL_ba5f73bc04a04df1bec10ec485127439",
              "IPY_MODEL_faaa3db108f54b2b8cc68d26f814cb87"
            ],
            "layout": "IPY_MODEL_4f08bd4dab974813aa757ec9c4aa963a"
          }
        },
        "ccf0334b4758450892167661416980ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce12ae54e3424ac8835ab37b5d2538a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6116981916849eebf946d98ae8691e0",
            "placeholder": "​",
            "style": "IPY_MODEL_779f2ee7130e4d44b213dab4098672e2",
            "value": "config.json: 100%"
          }
        },
        "d1773c06eeee4678953761276e51dcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d22750241cf04e32a11e7bc3a68cc2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da31decacd0a49fd8804be39dfab86f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_796ec3b798154839bfba5d5f26ba0eb2",
            "placeholder": "​",
            "style": "IPY_MODEL_2c02a1c5ce2e44efbe2052dcc585b8ab",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ed62cedbc6024c61b76131f992e31af2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1cace3748c49999acec51380c87808": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e8f141bc434de6826b9d288710ae71",
            "placeholder": "​",
            "style": "IPY_MODEL_cbcadf9a603b48acb63dae5b8ae018e3",
            "value": "vocab.txt: 100%"
          }
        },
        "f347b06929df4fab84b1ab26338f4af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f55f34da36fb4016a4a0494086c64641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b1d585d85824f888d39522ecb8a6f1f",
              "IPY_MODEL_5c3f767339684ba894d39282b9edbbb7",
              "IPY_MODEL_fad322935e6b4fbc8276abc2b85e1836"
            ],
            "layout": "IPY_MODEL_4be9692e8be043c489f06a3abf27c64d"
          }
        },
        "f864969ec82b4317ba1e703c1c8d22c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faaa3db108f54b2b8cc68d26f814cb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9463b08a33e4bdeaa2f13f307c94a4e",
            "placeholder": "​",
            "style": "IPY_MODEL_8d73beaf48cf49d39b0e0282883443a3",
            "value": " 232k/232k [00:00&lt;00:00, 2.99MB/s]"
          }
        },
        "fad322935e6b4fbc8276abc2b85e1836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033667bb55444c3f9f629dd9ede1ec99",
            "placeholder": "​",
            "style": "IPY_MODEL_d1773c06eeee4678953761276e51dcf1",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 34.5kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
